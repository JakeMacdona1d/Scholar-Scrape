publications = [
{"title": "Effective team interaction for adaptive training and situation awareness in human-autonomy teaming", "author": "Mustafa Demir, Nathan J McNeese, Craig Johnson, Jamie C Gorman, David Grimm, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:GnPB-g6toBAC", "abstract": "OBJECTIVE: >The aim of this exploratory paper is to underline the importance of coordination-based training for dynamic tasks in human-autonomy teaming. We address training solutions to distinct types of failures caused by either internal (the system) and external sources (the dynamic task environment). In order to accomplish this, we explore Human-Autonomy teaming communication and coordination with comprehensive scenarios drawn from the pilot tests and look at team needs to successfully overcome complex and dynamic failures. Findings from these two failure events are two-fold: (1) in order to adapt to dynamic environments and overcome unexpected failures, teams should receive role-related training (static and knowledge-based) as well as training about how to interact with one another (dynamic and coordination-based) and (2) designing synthetic agents with effective team coordination mechanisms will help\u00a0\u2026", "issued": "2019/4/8"},
{"title": "Flash crashes in multi-agent systems using minority games and reinforcement learning to test ai safety", "author": "Lorenzo Barberis Canonico, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:HoB7MX3m0LUC", "abstract": "OBJECTIVE: >As AI advances and becomes more complicated, it becomes necessary to study the safety implications of its behavior. This paper expands upon prior AI-safety research to create a model to study the harmful outcomes of multi-agent systems. In this paper, we outline previous work that has highlighted multiple aspects of AI-safety research and focus on AI-safety systems in multi-agent systems. After overviewing previous literature, we present a model focused on flash crashes, a concept often found in economics. The model was constructed using an interdisciplinary approach that includes game theory, machine learning, cognitive science and systems theory to study flash crashes in complex human-AI systems. We use the model to study a complex interaction between AI-agents, and our results indicate the multi-agent system in question is prone to cause flash crashes.", "issued": "2019/12/8"},
{"title": " An ideal human expectations of AI teammates in human-AI teaming", "author": "Rui Zhang, Nathan J McNeese, Guo Freeman, Geoff Musick", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:D03iK_w7-QYC", "abstract": "OBJECTIVE: >Driven by state-of-the-art AI technologies, human-AI collaboration has become an important area in computer-supported teamwork research. While human-AI collaboration has been investigated in various domains, more research is needed to explore human perceptions and expectations of AI teammates in human-AI teaming. To achieve an in-depth understanding of how people perceive AI teammates and what they expect from AI teammates in human-AI teaming, we conducted a survey with 213 participants and a follow-up interview with 20 participants. Considering the context-dependency of teamwork, we chose to study human-AI teaming in the context of multiplayer online games as a case study. This study shows that people have mixed feelings toward AI teammates but hold a positive attitude toward future collaboration with AI teammates in general. Our findings highlight people's expectations for AI\u00a0\u2026", "issued": "2021/1/5"},
{"title": "Designing human-autonomy teaming experiments through reinforcement learning", "author": "Beau Schelble, Lorenzo-Barberis Canonico, Nathan McNeese, Jack Carroll, Casey Hird", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:_xSYboBqXhAC", "abstract": "OBJECTIVE: >This paper creates and defines a framework for building and implementing human-autonomy teaming experiments that enable the utilization of modern reinforcement learning models. These models are used to train artificial agents to then interact alongside humans in a human-autonomy team. The framework was synthesized from experience gained redesigning a previously known and validated team task simulation environment known as NeoCITIES. Through this redesign, several important high-level distinctions were made that regarded both the artificial agent and the task simulation itself. The distinctions within the framework include gamification, access to high-performance computing, a proper reward function, an appropriate team task simulation, and customizability. This framework enables researchers to create experiments that are more usable for the human and more closely resemble real-world human\u00a0\u2026", "issued": "2020/12"},
{"title": "Team situation awareness within the context of human-autonomy teaming", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:hFOr9nPyWt4C", "abstract": "OBJECTIVE: >Effective team communication, a fundamental part of team coordination, is crucial for both effective Team Situation Awareness (TSA) and team performance. In this study, we looked at the role that team interaction (i.e., more specifically team verbal behaviors) played in TSA and team performance in order to better understand Human-Autonomy Teaming (HAT). We first analyzed team verbal behaviors (i.e., pushing and pulling information) across conditions of human-autonomy teams and human-human teams, and then analyzed their relationship with TSA and team performance via Growth Curve Modelling (GCM). Good teamwork involves anticipating the needs of teammates and that means pushing information before it is requested. Therefore, if things are going well, there should be little need for pulling information. In this study\u2019s task, participants were instructed to push information to others, and over time master\u00a0\u2026", "issued": "2017/12/1"},
{"title": "Training and verbal communications in human-autonomy teaming under degraded conditions", "author": "Craig J Johnson, Mustafa Demir, Garrett M Zabala, Hongbei He, David A Grimm, Cody Radigan, Alexandra T Wolff", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:zA6iFVUQeVQC", "abstract": "OBJECTIVE: >Verbal communication is important for coordination and performance in many team settings. However, the inclusion of autonomous artificial agents presents challenges to teamwork. This study sought to examine the effects of three different training approaches on team communication behaviors in human-autonomy teams (HATs) under normal and degraded conditions. Teams were split into three conditions prior to execution of missions in a remotely piloted aircraft system task environment: coordination training, calibration training, and control training. Analysis of text communications indicated that teams that received coordination training push information more frequently compared to teams that received control or calibration training, though this effect appeared to diminish over time. Teams in all three conditions pulled information equally, with a reduction in frequency over time. It was also found that teams that\u00a0\u2026", "issued": "2020/8/24"},
{"title": "Gaming as family time: Digital game co-play in modern parent-child relationships", "author": "Geoff Musick, Guo Freeman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:XiSMed-E-HIC", "abstract": "OBJECTIVE: >The role of digital gaming on parenthood and parent-child relationships is a common research interest in HCI and CHI PLAY. Yet, how technology co-use, such as co-playing digital games, affords and impacts parent-child relationships is still understudied. Using 20 in-depth interviews of adults who had co-played modern digital games with their parents and/or children, in this paper we investigate parent-child relationships mediated by co-playing modern digital games. We update prior HCI and CHI PLAY research on game-mediated parent-child relationships by suggesting a \"democratized\" family life and a fading digital divide for families with favorable digital game co-play experiences. We also contribute to HCI and CHI PLAY by providing new perspectives of technology co-use in the context of gaming, such as an important relational tool that parents can use to promote conversations with their child(ren). These\u00a0\u2026", "issued": "2021/10/6"},
{"title": "The purposeful presentation of ai teammates: Impacts on human acceptance and perception", "author": "Christopher Flathmann, Beau G Schelble, Nathan J McNeese, Bart Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:SdhP9T11ey4C", "abstract": "OBJECTIVE: >The paper reports on two empirical studies that provide the first examination into how the presentation of an AI teammate\u2019s identity, responsibility, and capability impacts humans\u2019 perception surrounding AI teammate adoption before interacting as teammates. Study 1\u2019s results indicated that AI teammates are accepted when they share equal responsibility on a task with humans, but other perceptions such as job security generally decline the more responsibility AI teammates have. Study 1 also revealed that identifying an AI as a tool instead of a teammate can have small benefits to human perceptions of job security and adoption. Study 2 revealed that the negative impacts of increasing responsibility can be mitigated by presenting AI teammates\u2019 capabilities as being endorsed by coworkers and one\u2019s own past experience. This paper discusses how to use these results to best balance the presentation of AI teammates\u00a0\u2026", "issued": "2023/9/10"},
{"title": "The effect of recommendation source and justification on professional development recommendations for high school teachers", "author": "Lijie Guo, Christopher Flathmann, Reza Anaraky, Nathan McNeese, Bart Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:B3FOqHPlNUQC", "abstract": "OBJECTIVE: > This paper describes a study conducted in the process of building a recommender system that provides personalized professional development pathways for high school teachers seeking to increase their disciplinary knowledge and/or their teaching skills. A controlled experiment (N = 190) was conducted to study the effects of the presented justification for the recommendations (teachers\u2019 needs vs. their interests) and the presented source of the recommendations (a human expert vs. an AI algorithm) on users\u2019 perceptions of and experience with the system. Our results show an interaction effect between these two system aspects: users who are told that the recommendations are based on their interests have a better experience when the recommendations are presented as originating from an AI algorithm, while users who are told that the recommendations are based on their needs have a better experience when\u00a0\u2026", "issued": "2022/6/28"},
{"title": "Using human-agent teams to purposefully design multi-agent systems", "author": "Christopher Flathmann, Nathan McNeese, Lorenzo Barberis Canonico", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:70eg2SAEIzsC", "abstract": "OBJECTIVE: >With multi-agent teams becoming more of a reality every day, it is important to create a common design model for multi-agent teams. These teams need to be able to function in dynamic environments and still communicate with any humans that may need a problem solved. Existing human-agent research can be used to purposefully create multi-agent teams that are interdependent but can still interact with humans. Rather than creating dynamic agents, the most effective way to overcome the dynamic nature of modern workloads is to create a dynamic team configuration, rather than individual member-agents that can change their roles. Multi-agent teams will require a variety of agents to be designed to cover a diverse subset of problems that need to be solved in the modern workforce. A model based on existing multi-agent teams that satisfies the needs of human-agent teams has been created to serve as a baseline\u00a0\u2026", "issued": "2019/11"},
{"title": "Exploring graduate students\u2019 collaborative problem-solving in engineering design tasks", "author": "Danielle Herro, Nathan McNeese, Robert O\u2019Hara, Kristin Frady, Debi Switzer", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:P5F9QuxV20EC", "abstract": "OBJECTIVE: >This study explored seven engineering graduate students\u2019 collaborative problem-solving (CPS) skills while working in interdisciplinary teams. Students worked in two different teams, in face-to-face and online environments, to solve complex manufacturing design challenges posed by their instructor. The students were assessed using an observational rubric with four dimensions: <i>peer interactions</i>, <i>positive communication</i>, <i>tools and methods</i> and <i>iteration and adaption</i>, and scored via each dimension\u2019s associated attributes, and subsequently interviewed. Six students scored emergent or proficient in CPS and had slightly higher CPS scores during the second observation. One student demonstrated a limited ability for CPS and the observable CPS skills decreased during the project. Interviews revealed the importance of (1) relying on instructor and student chosen technologies for collaborative tasks, (2) recognising\u00a0\u2026", "issued": "2021/9/2"},
{"title": "Modeling and guiding the creation of ethical human-AI teams", "author": "Christopher Flathmann, Beau G Schelble, Rui Zhang, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:KxtntwgDAa4C", "abstract": "OBJECTIVE: >With artificial intelligence continuing to advance, so too do the ethical concerns that can potentially negatively impact humans and the greater society. When these systems begin to interact with humans, these concerns become much more complex and much more important. The field of human-AI teaming provides a relevant example of how AI ethics can have significant and continued effects on humans. This paper reviews research in ethical artificial intelligence, as well as ethical teamwork through the lens of the rapidly advancing field of human-AI teaming, resulting in a model demonstrating the requirements and outcomes of building ethical human-AI teams. The model is created to guide the prioritization of ethics in human-AI teaming by outlining the ethical teaming process, outcomes of ethical teams, and external requirements necessary to ensure ethical human-AI teams. A final discussion is presented on how\u00a0\u2026", "issued": "2021/7/21"},
{"title": "Communication and teamwork during telemedicine-enabled stroke care in an ambulance", "author": "Anjali Joseph, Kapil Chalil Madathil, Roxana Jafarifiroozabadi, Hunter Rogers, Sahar Mihandoust", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:b0M2c_1WBrUC", "abstract": "OBJECTIVE: >The purpose of this study is to understand the communication among care teams during telemedicine-enabled stroke consults in an ambulance.BACKGROUND: >Telemedicine can have a significant impact on acute stroke care by enabling timely intervention in an ambulance before a patient reaches the hospital. However, limited research has been conducted on understanding and supporting team communication during the care delivery process for telemedicine-enabled stroke care in an ambulance.METHODS: >Video recordings of 13 simulated stroke telemedicine consults conducted in an ambulance were coded to document the tasks, communication events, and flow disruptions during the telemedicine-enabled stroke care delivery process.", "issued": "2022/2"},
{"title": "An Empirical Exploration of Resilience in Human-Autonomy Teams Operating Remotely Piloted Aircraft Systems", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke, David A Grimm, Jamie C Gorman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:lSLTfruPkqcC", "abstract": "OBJECTIVE: >Team resilience is an interactive and dynamic process that develops over time while a team maintains performance. This study aims to empirically investigate systems-level resilience in a Remotely Piloted Aircraft (RPA) System simulated task environment by examining team interaction during novel events. The approach used in the current study to measure systems-level resilience was developed by Hoffman &amp; Hancock (2017). In their conceptual study, resilience was considered a key feature of success in emerging complex sociotechnical systems; in our case, that is applied to Human-Autonomy Teams (HATs). Hoffman and Hancock conceptualized a resilience measure dynamically by means of several components, such as the time it took the system to recognize and characterize anomalies, and the time taken to specify and achieve new goals. In their framework, there were two main sub-events\u00a0\u2026", "issued": "2019/11"},
{"title": "Reflections on Team Simulations\u2014Part II: Contemporary Progressions", "author": "Michael D McNeese, Michael D McNeese, Lisa A Delise, Joan R Rentsch, Clifford E Brown", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:nb7KW1ujOQ8C", "abstract": "OBJECTIVE: >This chapter presents part II of our work and research perspective in                         utilizing team simulations as a primary means of conducting contemporary                         research within distributed team cognition. The chapter begins with a review                         and delves into specific research issues that are unmistakably coupled with                         the interrelationships among teamwork, cognition, technologies, and context.                         The chapter then articulates actual research findings from the use of                         various simulations that have advanced distributed team cognition to                         formulate the field it is today. Finally, a comprehensive framework is                         presented as a way to think about and conduct research within distributed                         team cognition. At the heart of the chapter is the idea that                         interdisciplinary research science is necessary as a worldview to bring\u00a0\u2026", "issued": "2020/9/28"},
{"title": "Overcoming the lumberjack effect through adaptive autonomy", "author": "Allyson I Hauptman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:mvPsJ3kp5DgC", "abstract": "OBJECTIVE: >Research shows that there are a variety of performance advantages to increasing the degrees of autonomy that human-supporting autonomous systems possess, including organizational productivity and the reduction of human workload. Yet, not all the consequences of increasing autonomy are positive. One such negative consequence is the risk of human operators becoming more incapable of responding to system failures as autonomy levels increase, a phenomenon known as the Lumberjack Effect. This paper proposes a conceptual model for using adaptive autonomy as a means to avoid the risks of this phenomenon while retaining the advantages of higher autonomy levels in earlier stages of an organization\u2019s work cycle. We apply our model to two research-based scenarios and discuss future research necessary to validate the model. This model provides the Human Factors community with a possible\u00a0\u2026", "issued": "2022/9"},
{"title": "Special issue on human-AI teaming and special issue on AI in healthcare", "author": "Mica R Endsley, Nancy Cooke, Nathan McNeese, Ann Bisantz, Laura Militello, Emilie Roth", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:VOx2b1Wkg3QC", "abstract": "OBJECTIVE: >Building upon advances in machine learning, software that depends on artificial intelligence (AI) is being introduced across a wide spectrum of systems, including healthcare, autonomous vehicles, advanced manufacturing, aviation, and military systems. Artificial intelligence systems may be unreliable or insufficiently robust; however, due to challenges in the development of reliable and robust AI algorithms based on datasets that are noisy and incomplete, the lack of causal models needed for projecting future outcomes, the presence of undetected biases, and noisy or faulty sensor inputs. Therefore, it is anticipated that for the foreseeable future, AI systems will need to operate in conjunction with humans in order to perform their tasks, and often as a part of a larger team of humans and AI systems. Further, AI systems may be instantiated with different levels of autonomy, at different times, and for different types of tasks\u00a0\u2026", "issued": "2022/12"},
{"title": "Effect of Mental Fatigue on Trust and Workload with AI-enabled Infrastructure Visual Inspection Systems", "author": "Snowil Lopes, Kapil Chalil Madathil, Jeffrey Bertrand, Camden Brady, Da Li, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:q3oQSFYPqjQC", "abstract": "OBJECTIVE: >The visual inspection domain has been impacted by recent technological advancements facilitating the pairing of Artificial Intelligence (AI) with automation, transforming this time-and personnel-intensive routine task into one able to be performed remotely using drones with the human in the role of co-collaborator (Agnisarman et al., 2019). However, as previous research has found, human trust and task workload, two essential elements for successful human-automation interaction, are impacted by the reliability of the automation: a decrease in reliability reduces human trust (Lee &amp; See, 2004; Muir &amp; Moray, 1996) and increases task workload (Lee &amp; See, 2004; Dixon &amp; Wickens, 2004). Similarly, the fatigue of the human, one of the leading contributors to errors and accidents in the aviation (Isaac et al., 2002) and automotive (Fritzsche et al., 2014) domains, has also been found to affect trust in automation, with the\u00a0\u2026", "issued": "2022/9"},
{"title": "Lets think together! Assessing shared mental models, performance, and trust in human-agent teams", "author": "Beau G Schelble, Christopher Flathmann, Nathan J McNeese, Guo Freeman, Rohit Mallick", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:K3LRdlH-MEoC", "abstract": "OBJECTIVE: >An emerging research agenda in Computer-Supported Cooperative Work focuses on human-agent teaming and AI agent's roles and effects in modern teamwork. In particular, one understudied key question centers around the construct of team cognition within human-agent teams. This study explores the unique nature of team dynamics in human-agent teams compared to human-human teams and the impact of team composition on perceived team cognition, team performance, and trust. In doing so, a mixed-method approach, including three team composition conditions (all human, human-human-agent, human-agent-agent), completed the team simulation NeoCITIES and completed shared mental model, trust, and perception measures. Results found that human-agent teams are similar to human-only teams in the iterative development of team cognition and the importance of communication to accelerating its\u00a0\u2026", "issued": "2022/1/14"},
{"title": "Adapting to the human: A systematic review of a decade of human factors research on adaptive autonomy", "author": "Allyson I Hauptman, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:35r97b3x0nAC", "abstract": "OBJECTIVE: >This systematic review provides an understanding of existing human factors research on adaptive autonomy, its design, its impacts, and its definition. We conducted a search on <i>adaptive autonomy</i> and additional relevant search terms in four databases, which produced an initial 245 articles. The application of inclusion and exclusion criteria produced a total of 60 articles for in-depth review. Through a collaborative coding process and analysis, we extracted triggers for and types of autonomy adaptations, as well as human factors dependent variables that have been studied in previous adaptive autonomy research. Based on this analysis, we present a definition of <i>adaptive autonomy</i> for use in human factors artificial intelligence research, as well as a comprehensive review of existing research contributions, notable research gaps, and the application of adaptive autonomy.", "issued": "2024/10/1"},
{"title": "A Comparative Evaluation of Formed Team Perception when in Human-Human and Human-Autonomous Teams", "author": "Chandni Murmu, Gnaanavarun Parthiban, Konnor McDowell, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:hkOj_22Ku90C", "abstract": "OBJECTIVE: >In recent years, there has been a surge in studies on Human and Autonomous Agent (AA) teams (HAT) within Human-Computer Interaction (HCI). However, the current literature lacks unbiased evaluations of applied AA or AI teammates compared to human counterparts in HAT settings. Existing evaluations are often influenced by participants\u2019 prior experiences and expectations, rather than providing a current assessment. To address this gap, we conducted a single-blind preliminary study, assessing the perceptions of 10 participants in Human-Human and Human-AA teams using the Paladins Multiplayer Online Games (MPOG) platform.", "issued": {"date-parts":[[2018]]}},
{"title": "Recommendations with benefits: exploring explanations in information sharing recommender systems for temporary teams", "author": "Geoff Musick, Allyson I Hauptman, Christopher Flathmann, Nathan J McNeese, Bart P Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:PR6Y55bgFSsC", "abstract": "OBJECTIVE: >Increased use of collaborative technologies and agile teamwork models has led to a greater need for temporary teams. Unfortunately, they lack the normal team formation processes that traditional teams use. Information sharing recommender systems can be used to share information about team members amongst the team; however, these systems rely on the team members themselves to disclose valuable information. While prior research has shown that an effective way to encourage user disclosure is through explanations to the user about what benefits they will gain from disclosure, the timing of such explanations has yet to be consideblack. In a between-subjects study with 150 participants, we assessed the content and timing of explanations on levels of disclosure in temporary teams. Our results indicate that providing benefit-related explanations during the time of disclosure can increase user disclosure, and\u00a0\u2026", "issued": "2023/11/16"},
{"title": "Exploring indie game development: Team practices and social experiences in A creativity-centric technology community", "author": "Guo Freeman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:BqipwSGYUEgC", "abstract": "OBJECTIVE: >The emergence of various interest-based online communities has led to the popularity of new forms of distributed creative teamwork such as citizen science, crowdsourcing, and open source software development. These new phenomena further complicate the context and content of distributed creative teamwork: what are the characteristics of these new forms of creative teams? And how do they shape people\u2019s perceptions and social experiences of distributed creative teams? In this paper, we report our empirical research of the team characteristics and practices in a creativity-centric technology community (i.e., independent [indie] game development) in hopes of exploring these questions. Our findings show that 1) indie game development teams are formed upon shared aspirations and use various strategies to collaborate with friends or online strangers; and their team practices are achieved through a balance\u00a0\u2026", "issued": "2019/6/15"},
{"title": "Human-autonomy Teaming: Need for a guiding team-based framework?", "author": "Christopher Flathmann, Nathan J McNeese, Eduardo Salas", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:olpn-zPbct0C", "abstract": "OBJECTIVE: >Whereas high-performance teamwork has been studied empirically for 70 years, a new form of teaming is on the rise. Enabled through the rapid progression of artificial intelligence, a human-autonomy team (HAT) involves one or more autonomous computerized agents collaborating with humans on interdependent tasks toward the achievement of a common goal. Whereas research on HATs is exploding in recent years, that research has not strongly embraced the vast literature, theory, and methods already developed in the all-human teaming literature. Moreover, definitional and construct validity issues, in terms of what constitutes a HAT, persist in the literature. In the current article we offer construct clarity and we integrate the Input-Mediator-Output model from the high-performance teaming literature to help future researchers classify the variables under study, theorize deeper, and consolidate findings across\u00a0\u2026", "issued": "2023/9/1"},
{"title": "Psychosocial Portraits of Participation in a Virtual World: A Comparative Analysis of Roles and Motives Across Three Different Professional Development Subreddits", "author": "Subhasree Sengupta, Jasmina Tacheva, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:_Re3VWB3Y0AC", "abstract": "OBJECTIVE: >Work and learning are essential facets of our existence, yet women continue to face multiple restrictions that hinder and impede their professional outcomes. These restrictions are especially pronounced in the technical domains of Information technology and Computer science. This paper explores the power of informal online communities to act as a collective shield of care and support in resisting and disrupting gender-based barriers. By comparing three professional development forums on Reddit, we explore the emergent social roles and how these engender community extending support, solidarity, and collective enrichment. Through a novel exploration of psychosocial linguistic markers, we identify four roles and outline key signatures delineating differing motives, intent, and commitment to the community. Expanding prior research that distinguishes between communal and agentic dispositions of actors in\u00a0\u2026", "issued": "2024/4/10"},
{"title": "The innovation ecology: Collaborative information, community support, and policy in a creative technology community", "author": "Guo Freeman, Jeffrey Bardzell, Jeffrey Bardzell, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:NMxIlDl6LWMC", "abstract": "OBJECTIVE: > In this paper, we explore a network of distributed individuals\u2019 collective efforts to establish an innovation ecology allowing them to engage in bottom up creative technological practices in today\u2019s information society. Specifically, we present an empirical study of the technological practices in an emerging creative technology community \u2013 independent [indie] game developers in the United States. Based on indie game developers\u2019 own accounts, we identified four themes that constitute an innovation ecology from the bottom up, including problem solving; collaborative information seeking, sharing, and reproducing; community support; and policy and politics. We argue that these findings inform our understanding of bottom up technological innovation and shed light on the design of sociotechnical systems to mediate and support such innovation beyond the gaming context.", "issued": {"date-parts":[[2019]]}},
{"title": "Privacy and Trust in HCI", "author": "Bart P Knijnenburg, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:-_dYPAW6P2MC", "abstract": "OBJECTIVE: >This chapter presents a high-level overview of HCI-relevant research on privacy and trust. While this chapter mostly presents timeless aspects of privacy and trust, it aims to offer a primer targeted at researchers and practitioners who work on contemporary computing technologies, in particular artificial intelligence (AI) systems and social technologies. The two main components of this primer are a section covering theoretical perspectives that can be employed to conceptualize privacy and trust, and a section covering the methods that can be employed to measure these concepts. Specific opportunities for HCI researchers and practitioners are provided throughout this chapter.", "issued": "2024/8/2"},
{"title": "What you say vs what you do: Utilizing positive emotional expressions to relay AI teammate intent within human-AI teams", "author": "Rohit Mallick, Christopher Flathmann, Wen Duan, Beau G Schelble, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:uJ-U7cs_P_0C", "abstract": "OBJECTIVE: >With the expansive growth of AI\u2019s capabilities in recent years, researchers have been tasked with developing and improving human-centered AI collaborations, necessitating the creation of human-AI teams (HATs). However, the differences in communication styles between humans and AI often prevent human teammates from fully understanding the intent and needs of AI teammates. One core difference is that humans naturally leverage a positive emotional tone during communication to convey their confidence or lack thereof to convey doubt in their ability to complete a task. Yet, this communication strategy must be explicitly designed in order for an AI teammate to be human-centered. In this mixed-methods study, 45 participants completed a study examining how human teammates interpret the behaviors of their AI teammates when they express different positive emotions via specific words/phrases. Quantitative\u00a0\u2026", "issued": "2024/8/13"},
{"title": "Dyadic team interaction and shared cognition to inform human-robot teaming", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:k_IJM867U9cC", "abstract": "OBJECTIVE: ><i>Project overview.</i> The current research aims to understand how human operators effectively team with urban search robot teammates in a dynamic and complex task environment. With that in mind, we examined how shared cognition and restricted language capabilities impact performance of human dyadic teams using a simulated Minecraft task environment. In this human dyadic team, an internal teammate (comparable to robot) identifies the location of victims while navigating inside a game environment that reflects a collapsed building; and an external teammate (comparable to operator) sees their teammate's actions from a different screen and guides them through the environment, tracking the location of victims on a map as they go. In order to examine the effects of language and shared cognition, a two by two design was chosen: (1) in the communication manipulation, participants are either able to\u00a0\u2026", "issued": "2018/9"},
{"title": "Developing human-robot team interdependence in a synthetic task environment", "author": "Glenn J Lematta, Pamela B Coleman, Shawaiz A Bhatti, Erin K Chiou, Nathan J McNeese, Mustafa Demir", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:O3NaXMp0MMsC", "abstract": "OBJECTIVE: >In future urban search and rescue teams, robots may be expected to conduct cognitive tasks. As the capabilities of robots change, so too will their interdependence with human teammates. Human factors and cognitive engineering are well-positioned to guide the design of autonomy for effective teaming. Previous work in the urban search and rescue synthetic task environment (USAR-STE) used Minecraft, a customizable gaming platform. In this effort, we advanced the USAR-STE by increasing interdependence in dyadic human-robot teaming through the Coactive Design framework. In this framework, we defined required capacities of victim identification in USAR from literature, and used them as inputs for modeling interdependence, and determined recommendations that would enhance interdependence in the task environment. Although Coactive Design is typically used to design interdependence for robots or\u00a0\u2026", "issued": "2019/11"},
{"title": "The impact of perceived autonomous agents on dynamic team behaviors", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:iH-uZ7U-co4C", "abstract": "OBJECTIVE: >Adaptive complex team behaviors evolve dynamically and occur in many different environments. In this study, we examined the role of these behaviors and their relationship with team performance in the context of human-autonomy teams (HAT) and all-human teams. The HAT served as the \u201csynthetic\u201d condition in which two human team members were informed that the third team member was a \u201csynthetic\u201d agent; in the control condition, the team members were informed that the pilot was a remotely located human teammate. Following are the primary findings from this study: first, control teams demonstrated better performance than the synthetic teams; second, control teams were more active than the synthetic teams in terms of planning the task, and third, the behavioral passiveness of the synthetic teams (due to lack of planning) associated with diminished team performance. This suggests that the synthetic teams\u00a0\u2026", "issued": "2018/7/20"},
{"title": "Teaming with a synthetic teammate: Insights into human-autonomy teaming", "author": "Nathan J McNeese, Mustafa Demir, Nancy J Cooke, Christopher Myers", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:4JMBOYKVnBMC", "abstract": "OBJECTIVE: >Three different team configurations are compared with the goal of better understanding human-autonomy teaming (HAT).BACKGROUND: >Although an extensive literature on human-automation interaction exists, much less is known about HAT in which humans and autonomous agents interact as coordinated units. Further research must be conducted to better understand how all-human teams compare to HAT.METHODS: >In an unmanned aerial system (UAS) context, a comparison was made among three types of three-member teams: (1) synthetic teams in which the pilot role is assigned to a synthetic teammate, (2) control teams in which the pilot was an inexperienced human, and (3) experimenter teams in which an experimenter served as an experienced pilot. Ten of each type of team participated. Measures of team performance, target processing efficiency, team situation awareness, and team verbal behaviors\u00a0\u2026", "issued": "2018/3"},
{"title": "Who/What is My Teammate? Team Composition Considerations in Human-AI Teaming", "author": "Nathan J McNeese, Beau G Schelble, Lorenzo Barberis Canonico, Mustafa Demir", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:UxriW0iASnsC", "abstract": "OBJECTIVE: >There are many unknowns regarding the characteristics and dynamics of human-AI teams, including a lack of understanding of how certain human-human teaming concepts may or may not apply to human-AI teams and how this composition affects team performance. This article outlines an experimental research study that investigates essential aspects of human-AI teaming such as team performance, team situation awareness, and perceived team cognition in various mixed composition teams (human-only, human-human-AI, human-AI-AI, and AI-only) through a simulated emergency response management scenario. Results indicate dichotomous outcomes regarding perceived team cognition and performance metrics, as perceived team cognition was not predictive of performance. Performance metrics like team situational awareness and team score showed that teams composed of all human participants\u00a0\u2026", "issued": "2021/5/23"},
{"title": "Towards meaningfully integrating human-autonomy teaming in applied settings", "author": "Beau G Schelble, Christopher Flathmann, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:cFHS6HbyZ2cC", "abstract": "OBJECTIVE: >Technological advancement goes hand in hand with economic advancement, meaning applied industries like manufacturing, medicine, and retail are set to leverage new practices like human-autonomy teams. These human-autonomy teams call for deep integration between artificial intelligence and the human workers that make up a majority of the workforce. This paper identifies the core principles of the human-autonomy teaming literature relevant to the integration of human-autonomy teams in applied contexts and research due to this large scale implementation of human-autonomy teams. A framework is built and defined from these fundamental concepts, with specific examples of its use in applied contexts and the interactions between various components of the framework. This framework can be utilized by practitioners of human-autonomy teams, allowing them to make informed decisions regarding the\u00a0\u2026", "issued": "2020/11/10"},
{"title": "Understanding the impact and design of AI teammate etiquette", "author": "Christopher Flathmann, Nathan J McNeese, Beau Schelble, Bart Knijnenburg, Guo Freeman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:XiVPGOgt02cC", "abstract": "OBJECTIVE: >Technical and practical advancements in Artificial Intelligence (AI) have led to AI teammates working alongside humans in an area known as human-agent teaming. While critical past research has shown the benefit to trust driven by the incorporation of interaction rules and structures (i.e. etiquette) in both AI tools and robotic teammates, research has yet to explicitly examine etiquette for digital AI teammates. Given the historic importance of trust within human-agent teams, the identification of etiquette\u2019s impact within said teams should be paramount. Thus, this study empirically evaluates the impact of AI teammate etiquette through a mixed-methods study that compares AI teammates that either adhere to or ignore traditional etiquette standards for machine systems. The quantitative results show that traditional etiquette adherence leads to greater trust, perceived performance of the AI, and perceived performance of\u00a0\u2026", "issued": "2023/3/26"},
{"title": "Understanding human-AI cooperation through game-theory and reinforcement learning models", "author": "Beau Schelble, Christopher Flathmann, Lorenzo-Barberis Canonico, Nathan Mcneese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:a0OBvERweLwC", "abstract": "OBJECTIVE: >For years, researchers have demonstrated the viability and applicability of game theory principles to the field of artificial intelligence. Furthermore, game theory has been shown as a useful tool for researching human-machine interaction, specifically their cooperation, by creating an environment where cooperation can initially form before reaching a continuous and stable presence in a human-machine system. Additionally, recent developments in reinforcement learning artificial intelligence have led to artificial agents cooperating more efficiently with humans, especially in more complex environments. This research conducts an empirical study to understand how different modern reinforcement learning algorithms and game theory scenarios could create different cooperation levels in human-machine teams. Three different reinforcement learning algorithms (Vanilla Policy Gradient, Proximal Policy Optimization, and Deep Q-Network) and two different game theory scenarios (Hawk Dove and Prisoners dilemma) were examined in a large-scale experiment. The results indicated that different reinforcement learning models interact differently with humans with Deep-Q engendering higher cooperation levels. The Hawk Dove game theory scenario elicited significantly higher levels of cooperation in the human-artificial intelligence system. A multiple regression using these two independent variables also found a significant ability to predict cooperation in the human-artificial intelligence systems. The results highlight the importance of social and task framing in human-artificial intelligence systems and noted the importance of choosing reinforcement\u00a0\u2026", "issued": "2021/1"},
{"title": "Team coordination of team situation awareness in human-autonomy teaming", "author": "Mustafa Demir, Nathan J McNeese, Manrong She, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:RYcK_YlVTxYC", "abstract": "OBJECTIVE: >Team Situation Awareness (TSA), which is a part of team cognition, is a critical factor that influences team effectiveness. It can be defined as getting the right information from the right person within the right amount of time, in order to overcome an unexpected event (Gorman, Cooke, Pederson, Connor, &amp; DeJoode, 2005). TSA is developed and maintained through team interactions, allowing for the measurement of TSA based on team interaction (Cooke &amp; Gorman, 2009). In the current study, a specific measure, Coordinated Awareness of Situation by Teams (CAST) is used (Cooke &amp; Gorman, 2009). CAST evaluates the effectiveness and efficiency of team interaction under \u201croadblock\u201d scenarios (Gorman, Cooke, &amp; Winner, 2006). These roadblocks represent novel situations in the task and require effective team communication and coordination. Team members must assess the situation according to\u00a0\u2026", "issued": "2019/11"},
{"title": "Adapt and overcome: Perceptions of adaptive autonomous agents for human-AI teaming", "author": "Allyson I Hauptman, Beau G Schelble, Nathan J McNeese, Kapil Chalil Madathil", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:LPZeul_q3PIC", "abstract": "OBJECTIVE: >Rapid advances in AI technologies have caused teams to explore the use of AI agents as full, active members of the team. The complex environments that teams occupy require human team members to constantly adapt their behaviors, and thus the ability of AI teammates to similarly adapt to changing situations significantly enhances the team\u2019s chances to succeed. In order to design such agents, it is important that we understand not only how to identify the amount of autonomous control AI agents have over their decisions, but also how changes to this control cognitively affects the rest of the team. Professional organizations often break their work cycles into phases that set limits on the team members\u2019 actions, and we propose that a similar process could be used to define the autonomy levels of AI teammates. Cyber incident response is an ideal context for this proposal, as we were able to use incident response\u00a0\u2026", "issued": "2023/1/1"},
{"title": "Towards ethical AI: Empirically investigating dimensions of AI ethics, trust repair, and performance in human-AI teaming", "author": "Beau G Schelble, Jeremy Lopez, Claire Textor, Rui Zhang, Nathan J McNeese, Richard Pak", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:5Ul4iDaHHb8C", "abstract": "OBJECTIVE: >Determining the efficacy of two trust repair strategies (apology and denial) for trust violations of an ethical nature by an autonomous teammate.BACKGROUND: >While ethics in human-AI interaction is extensively studied, little research has investigated how decisions with ethical implications impact trust and performance within human-AI teams and their subsequent repair.METHODS: >Forty teams of two participants and one autonomous teammate completed three team missions within a synthetic task environment. The autonomous teammate made an ethical or unethical action during each mission, followed by an apology or denial. Measures of individual team trust, autonomous teammate trust, human teammate trust, perceived autonomous teammate ethicality, and team performance were taken.", "issued": "2024/4"},
{"title": "Refocusing human-AI interaction through a teamwork lens", "author": "Christopher Flathmann, Beau G Schelble, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:tkaPQYYpVKoC", "abstract": "OBJECTIVE: >Alongside the rapid development and progression of AI algorithms, parallel efforts have been made to apply AI algorithms to human-facing systems. Over the last few decades, computational systems have been mostly relegated to automating basic and repetitive tasks alongside humans, thus creating human\u2013automation interaction (Lee &amp; See, 2004). However, the last few years have seen major strides made in artificial intelligence (AI) allowing for more dynamic and complex problems to be solved. What separates the technologies is that automation is often task-oriented and lacks the flexibility to handle changes in the task it was designed for (known as brittleness), but AI has the capability to handle tasks with dynamic features and may even have the potential to handle multiple tasks in a dynamic environment, which also makes it more capable of working alongside humans in these environments (Wynne &amp; Lyons\u00a0\u2026", "issued": "2023/5/18"},
{"title": "Humans interacting with intelligent machines: At the crossroads of symbiotic teamwork", "author": "Michael D McNeese, Michael D McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:2P1L_qKh6hAC", "abstract": "OBJECTIVE: >Humans have a long history of interacting with many types of intelligent machines. The level and sophistication of this interaction will only continue to grow in upcoming years, as intelligent technology continues to advance from automation to autonomous capabilities. In this chapter, we provide a historical context on research that has been conducted on humans interacting with machines. Principles of <i>extraordinary human\u2013robotic interaction (EHRI)</i> are outlined to better understand effective and meaningful human\u2013robot interaction. Finally, a discussion regarding the design and development of EHRI is presented. In this section, we present frameworks on how to both study and design EHRI.", "issued": "2020/1/1"},
{"title": "The Power of the Blue Tick (): Ugandans\u2019 experiences and engagement on Twitter at the onset of the COVID-19 pandemic", "author": "Lynn Kirabo, Moses Namara, Nathan Mcneese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:SP6oXDckpogC", "abstract": "OBJECTIVE: > To raise awareness and communicate measures aimed at curbing the ongoing COVID-19 pandemic, the Ugandan government used a combination of traditional and social media platforms. This included nationally televised presidential addresses on early coping efforts. We examine the impact of these communications by using public Twitter data to explore Ugandans\u2019 experiences, conversations, and engagement leading up to, during, and after these addresses. We found that tweets from verified accounts received more user engagement than tweets from non-verified accounts. We also used a Louvian clustering algorithm to identify the topics around which tweet clusters occurred. Some topics were unique to Uganda\u2019s COVID-19 response, such as lockdown and truck drivers. Thematic analyses within the five clusters uncovered sub-themes on conversation dynamics, and Twitter use during the pandemic. Overall\u00a0\u2026", "issued": "2021/3/8"},
{"title": "Dynamical measurement of team resilience", "author": "David AP Grimm, Jamie C Gorman, Nancy J Cooke, Mustafa Demir, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:eq2jaN3J8jMC", "abstract": "OBJECTIVE: >Resilient teams overcome sudden, dynamic changes by enacting rapid, adaptive responses that maintain system effectiveness. We analyzed two experiments on human-autonomy teams (HATs) operating a simulated remotely piloted aircraft system (RPAS) and correlated dynamical measures of resilience with measures of team performance. Across both experiments, HATs experienced automation and autonomy failures, using a Wizard of Oz paradigm. Team performance was measured in multiple ways, using a mission-level performance score, a target processing efficiency score, a failure overcome score, and a ground truth resilience score. Novel dynamical systems metrics of resilience measured the timing of system reorganization in response to failures across RPAS layers, including vehicle, controls, communications layers, and the system overall. Time to achieve extreme values of reorganization and novelty\u00a0\u2026", "issued": "2023/12"},
{"title": "Investigating the effects of perceived teammate artificiality on human performance and cognition", "author": "Beau G Schelble, Christopher Flathmann, Nathan J McNeese, Thomas O\u2019Neill, Richard Pak, Moses Namara", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:sSrBHYA8nusC", "abstract": "OBJECTIVE: >Teammates powered by artificial intelligence (AI) are becoming more prevalent and capable in their abilities as a teammate. While these teammates have great potential in improving team performance, empirical work that explores the impacts of these teammates on the humans they work with is still in its infancy. Thus, this study explores how the inclusion of AI teammates impacts both the performative abilities of human-AI teams in addition to the perceptions those humans form. The current study found that participants perceiving their third teammate as artificial performed worse than those perceiving them as human. Furthermore, these performance differences were significantly moderated by the task\u2019s difficulty, with participants in the AI teammate condition significantly outperforming participants perceiving a human teammate in the highest difficulty task, which diverges from previous human-AI teaming literature\u00a0\u2026", "issued": "2023/8/9"},
{"title": "Designing for mutually beneficial decision making in human-agent teaming", "author": "Rohit Mallick, Sarvesh Sawant, Nathan McNeese, Kapil Chalil Madathil", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:eflP2zaiRacC", "abstract": "OBJECTIVE: >This paper presents a joint decision-making framework between human and artificial intelligent agents in an effort to create a cohesive team uninhibited by each other\u2019s actions. Based on the well-known Recognition Primed Decision-Making Model, our framework expands upon RPD\u2019s single decision maker to be more Human-Agent Teaming (HAT) oriented. Specifically, our framework includes three layers of shared cognition to ensure both a consistent level of transparency between members and the efficient completion of the task. The first layer provides itself as a foundation of expectations that provides familiarity recognition in a situation. The second layer categorizes the environmental features into relevant decisions informing the symbiotic nature of who should and how to enact decisions collaboratively, which is the third layer. Altogether, this mutually beneficial decision-making model emphasizes\u00a0\u2026", "issued": "2022/9"},
{"title": "The Role of Autonomy Levels and Contextual Risk in Designing Safer AI Teammates", "author": "Allyson I Hauptman, Beau G Schelble, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:evX43VCCuoAC", "abstract": "OBJECTIVE: >As AI becomes more intelligent and autonomous, the concept of human-AI teaming has become more realistic and attractive. Despite the promises of AI teammates, human-AI teams face new, unique challenges. One such challenge is the declining ability of human team members to detect and respond to AI failures as they become further removed from the AI\u2019s decision-making loop. In this study, we conducted virtual experiments with twelve experts in two different teaming contexts, cyber incident response and medical triage, to understand how contextual risk impacts human teammate situational awareness and failure performance over a human-AI team\u2019s action cycle. Our results indicate that situational awareness is more closely tied to context, while failure performance is more closely tied to the team\u2019s action cycle. These results provide the foundation for future research into using contextual risk in determining\u00a0\u2026", "issued": "2024/5/15"},
{"title": "Selective Sharing is Caring: Toward the Design of a Collaborative Tool to Facilitate Team Sharing.", "author": "Geoff Musick, Beau G Schelble, Rohit Mallick, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:5ugPr518TE4C", "abstract": "OBJECTIVE: >Temporary teams are commonly limited by the amount of experience with their new teammates, leading to poor understanding and coordination. Collaborative tools can promote teammate team mental models (eg, teammate attitudes, tendencies, and preferences) by sharing personal information between teammates during team formation. The current study utilizes 89 participants engaging in real-world temporary teams to better understand user perceptions of sharing personal information. Qualitative and quantitative results revealed unique findings including: 1) Users perceived personality and conflict management style assessments to be accurate and sharing these assessments to be helpful, but had mixed perceptions regarding the appropriateness of sharing; 2) Users of the collaborative tool had higher perceptions of sharing in terms of helpfulness and appropriateness; and 3) User feedback highlighted the need for tools to selectively share less data with more context to improve appropriateness and helpfulness while reducing the amount of time to read.", "issued": "2023/1/3"},
{"title": "Exploring the relationship between ethics and trust in human\u2013artificial intelligence teaming: A mixed methods approach", "author": "Claire Textor, Rui Zhang, Jeremy Lopez, Beau G Schelble, Nathan J McNeese, Guo Freeman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:geHnlv5EZngC", "abstract": "OBJECTIVE: >Advancements and implementations of autonomous systems coincide with an increased concern for the ethical implications resulting from their use. This is increasingly relevant as autonomy fulfills teammate roles in contexts that demand ethical considerations. As AI teammates (ATs) enter these roles, research is needed to explore how an AT\u2019s ethics influences human trust. This current research presents two studies which explore how an AT\u2019s ethical or unethical behavior impacts trust in that teammate. In Study 1, participants responded to scenarios of an AT recommending actions which violated or abided by a set of ethical principles. The results suggest that ethicality perceptions and trust are influenced by ethical violations, but only ethicality depends on the type of ethical violation. Participants in Study 2 completed a focus group interview after performing a team task with a simulated AT that committed ethical\u00a0\u2026", "issued": "2022/12"},
{"title": "Understanding the role of trust in human-autonomy teaming", "author": "Nathan McNeese, Mustafa Demir, Erin Chiou, Nancy Cooke, Giovanni Yanikian", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:JV2RwH3_ST0C", "abstract": "OBJECTIVE: >This study aims to better understand trust in human-autonomy teams, finding that trust is related to team performance. A wizard of oz methodology was used in an experiment to simulate an autonomous agent as a team member in a remotely piloted aircraft system environment. Specific focuses of the study were team performance and team social behaviors (specifically trust) of human-autonomy teams. Results indicate 1) that there are lower levels of trust in the autonomous agent in low performing teams than both medium and high performing teams, 2) there is a loss of trust in the autonomous agent across low, medium, and high performing teams over time, and 3) that in addition to the human team members indicating low levels of trust in the autonomous agent, both low and medium performing teams also indicated lower levels of trust in their human team members.", "issued": "2019/1/8"},
{"title": "The evolution of human-autonomy teams in remotely piloted aircraft systems operations", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:RGFaLdJalmkC", "abstract": "OBJECTIVE: >The focus of this current research is 2-fold: (1) to understand how team interaction in human-autonomy teams (HAT)s evolve in the Remotely Piloted Aircraft Systems (RPAS) task context, and (2) to understand how HATs respond to three types of failures (automation, autonomy, and cyber-attack) over time. We summarize the findings from three of our recent experiments regarding the team interaction within HAT over time in the dynamic context of RPAS. For the first and the second experiments, we summarize general findings related to team member interaction of a three-member team over time, by comparison of HATs with all-human teams. In the third experiment, which extends beyond the first two experiments, we investigate HAT evolution when HATs are faced with three types of failures during the task. For all three of these experiments, measures focus on team interactions and temporal dynamics consistent with the theory of interactive team cognition. We applied Joint Recurrence Quantification Analysis, to communication flow in the three experiments. One of the most interesting and significant findings from our experiments regarding team evolution is the idea of entrainment, that one team member (the pilot in our study, either agent or human) can change the communication behaviors of the other teammates over time, including coordination, and affect team performance. In the first and second studies, behavioral passiveness of the synthetic teams resulted in very stable and rigid coordination in comparison to the all-human teams that were less stable. Experimenter teams demonstrated metastable coordination (not rigid nor unstable) and\u00a0\u2026", "issued": "2019/9/6"},
{"title": "The Effect of AI Teammate Ethicality on Trust Outcomes and Individual Performance in Human-AI Teams.", "author": "Beau G Schelble, Caitlin Lancaster, Wen Duan, Rohit Mallick, Nathan J McNeese, Jeremy Lopez", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:J-pR_7NvFogC", "abstract": "OBJECTIVE: >This study improves the understanding of trust in human-AI teams by investigating the relationship of AI teammate ethicality on individual outcomes of trust (ie, monitoring, confidence, fear) in AI teammates and human teammates over time. Specifically, a synthetic task environment was built to support a three-person team with two human teammates and one AI teammate (simulated by a confederate). The AI teammate performed either an ethical or unethical action in three missions, and measures of trust in the human and AI teammate were taken after each mission. Results from the study revealed that unethical actions by the AT had a significant effect on nearly all of the outcomes of trust measured and that levels of trust were dynamic over time for both the AI and human teammate, with the AI teammate recovering trust in Mission 1 levels by Mission 3. AI ethicality was mostly unrelated to participants\u2019 trust in their fellow human teammates but did decrease perceptions of fear, paranoia, and skepticism in them, and trust in the human and AI teammate was not significantly related to individual performance outcomes, which both diverge from previous trust research in human-AI teams utilizing competency-based trust violations.", "issued": "2023/1/3"},
{"title": "Reflections on Team Simulations\u2014Part I: Historical Precedence", "author": "Michael D McNeese, Michael D McNeese, Lisa A Delise, Joan R Rentsch, Clifford E Brown", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:1sJd4Hv_s6UC", "abstract": "OBJECTIVE: >As we begin looking at research within distributed team cognition, two                         thoughts are paramount: (1) to realize where the emergence distributed team                         cognition has come from (i.e., its historical significance and character and                         (2) to understand the reciprocation and influences among teamwork,                         cognition, and technology advancement as a basis for development of the                         field. In particular, we draw upon the incredible amount of research work                         done that indelibly the result of team simulations. Much of our own work                         emerged from the use of technology-enabled team simulations. This chapter                         reviews this work along with earlier foundations that set up and                         substantiate the study of teams both for collocated and distributed                         settings. This chapter presents Part I of team simulation research that\u00a0\u2026", "issued": "2020/9/28"},
{"title": "The complex relationship of AI ethics and trust in human\u2013AI teaming: insights from advanced real-world subject matter experts", "author": "Jeremy Lopez, Claire Textor, Caitlin Lancaster, Beau Schelble, Guo Freeman, Rui Zhang", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:dTyEYWd-f8wC", "abstract": "OBJECTIVE: >Human-autonomy teams will likely first see use within environments with ethical considerations (e.g., military, healthcare). Therefore, we must consider how to best design an ethical autonomous teammate that can promote trust within teams, an antecedent to team effectiveness. In the current study, we conducted 14 semi-structured interviews with US Air Force pilots on the topics of autonomous teammates, trust, and ethics. A thematic analysis revealed that the pilots see themselves serving a parental role alongside a developing machine teammate. As parents, the pilots would feel responsible for their machine teammate\u2019s behavior, and their unethical actions may not lead to a loss of trust. However, once the pilots feel their teammate has matured, their unethical actions would likely lower trust. To repair that trust, the pilots would want to understand their teammate\u2019s processing, yet they are concerned about their\u00a0\u2026", "issued": "2023/7/5"},
{"title": "Balancing the Scales of Explainable and Transparent AI Agents within Human-Agent Teams", "author": "Sarvesh Sawant, Rohit Mallick, Camden Brady, Kapil Chalil Madathil, Nathan McNeese, Jeff Bertrand", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:dQ2og3OwTAUC", "abstract": "OBJECTIVE: >With the progressive nature of Human-Agent Teams becoming more and more useful for high-quality work output, there is a proportional need for bi-directional communication between teammates to increase efficient collaboration. This need is centered around the well-known issue of innate mistrust between humans and artificial intelligence, resulting in sub-optimal work. To combat this, computer scientists and humancomputer interaction researchers alike have presented and refined specific solutions to this issue through different methods of AI interpretability. These different methods include explicit AI explanations as well as implicit manipulations of the AI interface, otherwise known as AI transparency. Individually these solutions hold considerable merit in repairing the relationship of trust between teammates, but also have individual flaws. We posit that the combination of different interpretable mechanisms\u00a0\u2026", "issued": "2023/9"},
{"title": "Responsible Computing", "author": "KR Fleischmann, A McMillan-Major, EM Bender, B Friedman, D Saxena", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:7T2F9Uy0os0C", "abstract": "OBJECTIVE: >With great computing power must come responsible computing! Computing now impacts so many areas of our lives that a journal devoted to exploring the ethical and societal implications of computing is essential. Computing professionals must be at the forefront of raising questions and conducting research about how the technologies we help develop can best serve humanity in a responsible way.BACKGROUND: >The ACM Journal on Responsible Computing (JRC) aims to foster an interdisciplinary conversation connecting researchers and practitioners across a wide range of fields, including but not limited to computing, information, ethics, law, policy, communication, anthropology, sociology, psychology, political science, economics, and science and technology studies. Our vision for JRC is that it will be a home for outstanding research and a valued resource. We especially hope to attract articles that bring a convergent\u00a0\u2026", "issued": {"date-parts":[[2024]]}},
{"title": "Towards leveraging AI-Based moderation to address emergent harassment in social virtual reality", "author": "Kelsea Schulenberg, Li, Guo Freeman, Samaneh Zamanifard, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:WA5NYHcadZ8C", "abstract": "OBJECTIVE: >Extensive HCI research has investigated how to prevent and mitigate harassment in virtual spaces, particularly by leveraging human-based and Artificial Intelligence (AI)-based moderation. However, social Virtual Reality (VR) constitutes a novel social space that faces both intensified harassment challenges and a lack of consensus on how moderation should be approached to address such harassment. Drawing on 39 interviews with social VR users with diverse backgrounds, we investigate the perceived opportunities and limitations for leveraging AI-based moderation to address emergent harassment in social VR, and how future AI moderators can be designed to enhance such opportunities and address limitations. We provide the first empirical investigation into re-envisioning AI\u2019s new roles in innovating content moderation approaches to better combat harassment in social VR. We also highlight important\u00a0\u2026", "issued": "2023/4/19"},
{"title": "The impact of training on human\u2013autonomy team communications and trust calibration", "author": "Craig J Johnson, Mustafa Demir, Nathan J McNeese, Jamie C Gorman, Alexandra T Wolff, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:u9iWguZQMMsC", "abstract": "OBJECTIVE: >This work examines two human\u2013autonomy team (HAT) training approaches that target communication and trust calibration to improve team effectiveness under degraded conditions.BACKGROUND: >Human\u2013autonomy teaming presents challenges to teamwork, some of which may be addressed through training. Factors vital to HAT performance include communication and calibrated trust.METHODS: >Thirty teams of three, including one confederate acting as an autonomous agent, received either entrainment-based coordination training, trust calibration training, or control training before executing a series of missions operating a simulated remotely piloted aircraft. Automation and autonomy failures simulating degraded conditions were injected during missions, and measures of team communication, trust, and task efficiency were collected.", "issued": "2023/11"},
{"title": "Examining the Relationship Between an Autonomous Teammate\u2019s Ethical Decision Making and Trust", "author": "Jeremy Lopez, Claire Textor, Beau Schelble, Rui Zhang, Richard Pak, Nathan J McNeese, Guo Freeman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:Tiz5es2fbqcC", "abstract": "", "issued": "2021/11/3"},
{"title": "Language, Camera, Autonomy! Prompt-engineered Robot Control for Rapidly Evolving Deployment", "author": "Jacob P Macdonald, Rohit Mallick, Allan B Wollaber, Jaime D Pe\u00f1a, Nathan McNeese, Ho Chit Siu", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:Fu2w8maKXqMC", "abstract": "OBJECTIVE: >The Context-observant LLM-Enabled Autonomous Robots (CLEAR) platform offers a general solution for large language model (LLM)-enabled robot autonomy. CLEAR-controlled robots use natural language to perceive and interact with their environment: contextual description deriving from computer vision and optional human commands prompt intelligent LLM responses that map to robotic actions. By emphasizing prompting, system behavior is programmed without manipulating code, and unlike other LLM-based robot control methods, we do not perform any model fine-tuning. CLEAR employs off-the-shelf pre-trained machine learning models for controlling robots ranging from simulated quadcopters to terrestrial quadrupeds. We provide the open-source CLEAR platform, along with sample implementations for a Unity-based quadcopter and Boston Dynamics Spot\u00ae robot. Each LLM used, GPT-3.5, GPT-4, and\u00a0\u2026", "issued": "2024/3/11"},
{"title": "Clemson Universitys Teacher Learning Progression Program: Personalized Advanced Credentials for Teachers", "author": "Luke J Rapa, Jeff C Marshall, Stephanie M Madison, Christopher Flathmann, Bart P Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:p2g8aNsByqUC", "abstract": "OBJECTIVE: >This chapter provides an overview of Clemson University's Teacher Learning Progression program, which offers participating middle school science, technology, engineering, and/or mathematics (STEM) teachers with personalized advanced credentials. In contrast to typical professional development (PD) approaches, this program identifies individualized pathways for PD based on teachers' unique interests and needs and offers PD options through the use of a \u201crecommender system\u201d\u2014a system providing context-specific recommendations to guide teachers toward the identification of preferred PD pathways and content. In this chapter, the authors introduce the program and highlight (1) the data collection and instrumentation needed to make personalized PD recommendations,(2) the recommender system, and (3) the personalized advanced credential options. The authors also discuss lessons learned through\u00a0\u2026", "issued": {"date-parts":[[2022]]}},
{"title": "Evaluation and prediction of human error in ambulance-based telemedicine stroke assessment", "author": "Hunter Rogers, Amal Ponathil, Kapil Chalil Madathil, Anjali Joseph, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:pyW8ca7W8N0C", "abstract": "", "issued": "2020/12"},
{"title": "Evaluating Cross-Training\u2019s Impact on Perceived Teaming Outcomes for Human-AI Teams", "author": "Caitlin Lancaster, Hanna Gilreath, Rohit Mallick, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:VLnqNzywnoUC", "abstract": "OBJECTIVE: >The rapid integration of artificial intelligence (AI) across various industries has given rise to human-AI teams (HATs), where collaboration between humans and AI may leverage their unique strengths. However, these teams often face performance challenges due to mismatches between human expectations and AI capabilities, hindering the effectiveness of these future workforce teams. Addressing these discrepancies, team training, particularly cross-training, has emerged as a promising intervention to align expectations and enhance team dynamics. This study explores the efficacy of different cross-training approaches and human/AI team role assignments on team training reactions and perceived task performance in an advertising co-creation task. The findings suggest that cross-training significantly improves both training reactions and task performance perceptions. By extending traditional team training methods\u00a0\u2026", "issued": "2024/8/13"},
{"title": "Understanding human-robot teams in light of all-human teams: Aspects of team interaction and shared cognition", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:SeFeTyx0c_EC", "abstract": "OBJECTIVE: >As robots become more autonomous, their roles shift from being operated and controlled by humans to interactively teaming with humans. The current research focuses on how human operators can effectively team with autonomous urban search and rescue agents in a dynamic and complex task environment. To do so, we empirically examined how shared cognition and restricted language capabilities impacted performance of human-robot dyad search teams using a simulated Minecraft task environment. In order to examine the effects of shared mental models and language the following modified conditions were applied: (1) participants were either able to communicate using natural language or the internal participant's communication was limited to three-word utterances; and (2) shared mental models were manipulated by either the internal participant being made fully aware of the external participant's\u00a0\u2026", "issued": "2020/8/1"},
{"title": "Working together apart through embodiment: Engaging in everyday collaborative activities in social Virtual Reality", "author": "Guo Freeman, Dane Acena, Nathan J McNeese, Kelsea Schulenberg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:l7t_Zn2s7bgC", "abstract": "OBJECTIVE: >Computer-mediated collaboration has long been a core research interest in CSCW and HCI. As online social spaces continue to evolve towards more immersive and higher fidelity experiences, more research is still needed to investigate how emerging novel technology may foster and support new and more nuanced forms and experiences of collaboration in virtual environments. Using 30 interviews, this paper focuses on what people may collaborate on and how they collaborate in social Virtual Reality (VR). We broaden current studies on computer-mediated collaboration by highlighting the importance of embodiment for co-presence and communication, replicating offline collaborative activities, and supporting the seamless interplay of work, play, and mundane experiences in everyday lives for experiencing and conceptualizing collaboration in emerging virtual environments. We also propose potential design\u00a0\u2026", "issued": "2022/1/14"},
{"title": "2019 Index IEEE Systems, Man, and Cybernetics Magazine Vol. 5", "author": "J Abiva, C Ahn, F Alavi, O Anderson, B Baars, B Bouchon-Meunier", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:pqnbT2bcN3wC", "abstract": "", "issued": "2019/4"},
{"title": "Intelligent and Human-Centered Clinical Checklists: A Voice Interface for Virtualized Clinical Paths", "author": "Lorenzo Barberis, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:isC4tDSrTZIC", "abstract": "OBJECTIVE: >Healthcare practitioners today find themselves confronting a multitude of diverse and complex tasks while under time-sensitive conditions. This dynamic is particularly apparent in the operating room, where for each operation, doctors and nurses have to make sure each surgery condition is optimal to avoid surgery complications and the spread of infections. Checklists are a helpful tool to avoid glossing over these critical steps, but their current implementation is outdated and does not leverage human-centered technology. We propose a checklist design for operating rooms that is generated by an intelligent system and is interacted with through a voice interface. By removing this burden away from the nursing staff, routine safety procedures can be expedited, and practitioners can redirect their full attention to the operation at hand.", "issued": "2018/9"},
{"title": "A Comment on \u201cCan You Outsmart the Robot? An Unexpected Path to Work Meaningfulness\u201d by Bernadeta Go\u0161Tautait\u0117, Irina Liubert\u0117, Sharon K. Parker, and Ilona Bu\u010di\u016bnien\u0117: Calling \u2026", "author": "Thomas A O\u2019Neill, Christopher Flathmann, Nathan J McNeese, Samantha K Jones, Beau G Schelble", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:kzcrU_BdoSEC", "abstract": "OBJECTIVE: >The article \u201cCan You Outsmart the Robot? An Unexpected Path to Work Meaningfulness\u201d by Go\u0161tautait\u0117, Liubert\u0117, Parker, and Bu\u010di\u016bnien\u0117 (2023) examines how people handled the integration of industrial robots into two Lithuanian manufacturing facilities. We applaud the authors for this work and we hope scholars will continue to examine how humans can work in a healthy way alongside robots, artificial intelligence (AI), automation, and disembodied agent peers both now and in the future of work. In particular, much more fieldwork like this is needed to help guide our understanding of modern technological appropriation by humans. The article by Go\u0161tautait\u0117 et al.(2023) was concerned with human work meaningfulness in the context of low-reliability robots, as well as automation and autonomy more broadly. The authors offer several interesting observations about their findings that have important implications to\u00a0\u2026", "issued": "2024/3"},
{"title": "I see you: Examining the role of spatial information in human-agent teams", "author": "Beau G Schelble, Christopher Flathmann, Geoff Musick, Nathan J McNeese, Guo Freeman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:V3AGJWp-ZtQC", "abstract": "OBJECTIVE: >Awareness, and specifically, spatial awareness, has long played a pivotal role in Computer-Supported Cooperative Work research in both theory and design. This significant background gives awareness the ability to answer challenges facing human-agent teams in communication and shared understanding. As such, the current study investigates the effects of spatial information level (low, high) on the development of team cognition and its outcomes in varying compositions of human-agent teams (human-human-agent, human-agent-agent) versus human-only (human-human-human) teams. The mixed-methods study had teams complete several rounds of the NeoCITIES emergency response management simulation and complete various team cognition and perception measures, followed by qualitative free-response questions. The study found that human-only teams did not perform at the same level as human\u00a0\u2026", "issued": "2022/11/11"},
{"title": "Public Perceptions, Critical Awareness and Community Discourse on AI Ethics: Evidence from an Online Discussion Forum", "author": "Subhasree Sengupta, Swapnil Srivastava, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:JQOojiI6XY0C", "abstract": "OBJECTIVE: >As Artificial Intelligence (AI) become increasingly ingrained into society, ethical and regularity concerns become critical. Given the vast array of philosophical considerations of AI ethics, there is a pressing need to understand and balance public opinion and expectations of how AI ethics should be defined and implemented, such that it centers the voice of experts and non-experts alike. This investigation explores a subreddit r/aiethics through a multi-methodological, multi-level approach. The analysis yields six conversational themes, sentiment trends, and emergent roles that elicit narratives associated with expanding implementation, policy, critical literacy, communal preparedness, and increased awareness towards combining technical and social aspects of AI ethics. Such insights can help to distill necessary considerations for the practice of AI ethics beyond scholarly traditions and how informal spaces (such as virtual channels) can and should act as avenues of learning, raising critical consciousness, bolstering connectivity, and enhancing narrative agency on AI ethics.", "issued": "2024/1/3"},
{"title": "Towards human\u2013robot teaming: Tradeoffs of explanation-based communication strategies in a virtual search and rescue task", "author": "Erin K Chiou, Mustafa Demir, Verica Buchanan, Christopher C Corral, Mica R Endsley, Glenn J Lematta", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:738O_yMBCRsC", "abstract": "OBJECTIVE: >Autonomous robots have the potential to play a critical role in urban search and rescue (USAR) by allowing human counterparts of a response team to remain in remote, stable locations while the robots execute more dangerous work in the field. However, challenges remain in developing robot capabilities suitable for teaming with humans. Communicating effectively is one of these challenges, especially if plan deviations during field operations require robot explanation. A virtual USAR team task experiment was conducted in Minecraft with a confederate acting as the remote robot. Four explanation-based communication conditions were tested: (1) always explain\u2013the robot automatically provided explanations for any off-plan behaviors, (2) explain if asked\u2013the robot provided an explanation only when the human counterpart requests it, (3) pull prime\u2013the same as (2) but participants also experienced implicit\u00a0\u2026", "issued": "2022/7/1"},
{"title": "Collectively intelligent teams: Integrating team cognition, collective intelligence, and AI for future Teaming", "author": "Lorenzo Barberis Canonico, Christopher Flathmann, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:35N4QoGY0k4C", "abstract": "OBJECTIVE: >In this paper we propose a new model for teamwork that integrates team cognition, collective intelligence, and artificial intelligence. We do this by first characterizing what sets team cognition and collectively intelligence apart, and then reviewing the literature on \u201csuperforecasting\u201d and the ability for effectively coordinated teams to outperform predictions by large groups. Lastly, we delve into the ways in which teamwork can be enhanced by artificial intelligence through our model, finally highlighting the many areas of research worth exploring through interdisciplinary efforts.", "issued": "2019/11"},
{"title": "Breakups on social media: Social behaviors and dilemmas", "author": "Rui Zhang, Guo Freeman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:u_35RYKgDlwC", "abstract": "OBJECTIVE: >In this paper, we explore \"apart\" behaviors, which are conducted to disconnect with ex-partners using various technological affordances on social media, to extend CSCW/HCI knowledge of how social media supports disconnections in post-breakups. 174 posts and comments from Reddit, Quora, and Facebook, along with sixteen online articles, were qualitatively analyzed. Our findings show how users conduct apart behaviors using technological affordances and their expectations of features to facilitate apart behaviors. We also present two social dilemmas in experiencing apart behaviors on social media.", "issued": "2020/10/17"},
{"title": "The National Academies Board on Human-Systems Integration (BOHSI) Panel: Human-AI Teaming: Research Frontiers", "author": "Frederick L Oswald, Mica R Endsley, Jessie Chen, Erin K Chiou, Mark H Draper, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:D_sINldO8mEC", "abstract": "OBJECTIVE: >The National Academies recently issued a consensus study report summarizing the state of the art and research needs relating to Human-AI teaming, especially in the context of dynamic, high-risk environments such as multi-domain military operations. This consensus study was conducted by the National Academies Board on Human-Systems Integration (BOHSI). This panel, organized by BOHSI, brings together prominent researchers, including several members of the consensus committee, to discuss the state of the art and research frontiers for development of effective human-AI teams that can operate resiliently in complex, data intensive, and dynamically paced environments.", "issued": "2022/9"},
{"title": "\u201cIt\u2019s Everybody\u2019s Role to Speak Up... But Not Everyone Will\u201d: Understanding AI Professionals\u2019 Perceptions of Accountability for AI Bias Mitigation", "author": "Caitlin M Lancaster, Kelsea Schulenberg, Christopher Flathmann, Nathan J McNeese, Guo Freeman", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:ZuybSZzF8UAC", "abstract": "OBJECTIVE: >In this paper, we investigate the perceptions of AI professionals for their accountability for mitigating AI bias. Our work is motivated by calls for socially responsible AI development and governance in the face of societal harm but a lack of accountability across the entire socio-technical system. In particular, we explore a gap in the field stemming from the lack of empirical data needed to conclude how real AI professionals view bias mitigation and why individual AI professionals may be prevented from taking accountability even if they have the technical ability to do so. This gap is concerning as larger responsible AI efforts inherently rely on individuals who contribute to designing, developing, and deploying AI technologies and mitigation solutions. Through semi-structured interviews with AI professionals from diverse roles, organizations, and industries working on development projects, we identify that AI professionals\u00a0\u2026", "issued": "2024/3/20"},
{"title": "Leveraging Artificial Intelligence to Promote Awareness in Augmented Reality Systems", "author": "Wangfan Li, Rohit Mallick, Carlos Toxtli-Hernandez, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:tKAzc9rXhukC", "abstract": "OBJECTIVE: >Recent developments in artificial intelligence (AI) have permeated through an array of different immersive environments, including virtual, augmented, and mixed realities. AI brings a wealth of potential that centers on its ability to critically analyze environments, identify relevant artifacts to a goal or action, and then autonomously execute decision-making strategies to optimize the reward-to-risk ratio. However, the inherent benefits of AI are not without disadvantages as the autonomy and communication methodology can interfere with the human's awareness of their environment. More specifically in the case of autonomy, the relevant human-computer interaction literature cites that high autonomy results in an \"out-of-the-loop\" experience for the human such that they are not aware of critical artifacts or situational changes that require their attention. At the same time, low autonomy of an AI system can limit the human's own autonomy with repeated requests to approve its decisions. In these circumstances, humans enter into supervisor roles, which tend to increase their workload and, therefore, decrease their awareness in a multitude of ways. In this position statement, we call for the development of human-centered AI in immersive environments to sustain and promote awareness. It is our position then that we believe with the inherent risk presented in both AI and AR/VR systems, we need to examine the interaction between them when we integrate the two to create a new system for any unforeseen risks, and that it is crucial to do so because of its practical application in many high-risk environments.", "issued": "2024/4/23"},
{"title": "Towards Human-Robot Teaming: Tradeoffs of Explanation-Based Communication Strategies in a Virtual Search and Rescue Task (vol 14, pg 1117, 2022)", "author": "Erin K Chiou, Mustafa Demir, Verica Buchanan, Christopher C Corral, Mica R Endsley, Glenn J Lematta", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:PELIpwtuRlgC", "abstract": "", "issued": "2022/10/1"},
{"title": "Understanding and Mitigating Challenges for Non-Profit Driven Indie Game Development to Innovate Game Production", "author": "Guo Freeman, Li, Nathan Mcneese, Kelsea Schulenberg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:bnK-pcrLprsC", "abstract": "OBJECTIVE: >Non-profit driven indie game development represents a growing open and participatory game production model as an alternative to the traditional mainstream gaming industry. However, this community is also facing and coping with tensions and dilemmas brought by its focus on artistic and cultural values over economic benefits. Using 28 interviews with indie game developers with a non-profit agenda across various cultures, we investigate the challenges non-profit driven indie game developers face, which mainly emerge in their personal or collaborative labor and their endeavors to secure sustainable resources and produce quality products. Our investigation extends the current HCI knowledge of the democratization of technology and its impact on the trajectory of innovating, designing, and producing future (gaming) technologies. These insights may help increase the opportunities for and retention of previously\u00a0\u2026", "issued": "2023/4/19"},
{"title": "Communication Strategies in Human-Autonomy Teams During Technological Failures", "author": "Julie L Harrison, Shiwen Zhou, Matthew J Scalia, David AP Grimm, Mustafa Demir, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:uLbwQdceFCQC", "abstract": "OBJECTIVE: >This study examines low-, medium-, and high-performing Human-Autonomy Teams\u2019 (HATs\u2019) communication strategies during various technological failures that impact routine communication strategies to adapt to the task environment.BACKGROUND: >Teams must adapt their communication strategies during dynamic tasks, where more successful teams make more substantial adaptations. Adaptations in communication strategies may explain how successful HATs overcome technological failures. Further, technological failures of variable severity may alter communication strategies of HATs at different performance levels in their attempts to overcome each failure.METHODS: >HATs in a Remotely Piloted Aircraft System-Synthetic Task Environment (RPAS-STE), involving three team members, were tasked with photographing targets. Each triad had two randomly assigned participants in navigator and photographer\u00a0\u2026", "issued": "2024/1/9"},
{"title": "Trust and team performance in human\u2013autonomy teaming", "author": "Nathan J McNeese, Mustafa Demir, Erin K Chiou, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:yD5IFk8b50cC", "abstract": "OBJECTIVE: >This study aims to better understand trust in human\u2013autonomy teams, finding that trust is important for team performance. A Wizard of Oz approach was used to simulate an autonomous agent team member, in a remotely piloted aircraft system research environment, to study the relationship between trust and team performance in human\u2013autonomy teams. Results show that (1) there are lower levels of trust in the autonomous agent in low-performing teams compared with medium- or high-performing teams; (2) there is a loss of trust in the autonomous agent over time across low-, medium-, and high-performing teams; and (3) both low- and medium-performing teams indicated lower levels of trust in their human team members. These findings indicate that trust in a teammate (autonomous or human) is associated with team performance and that trust may evolve over time irrespective of team performance.", "issued": "2021/1/2"},
{"title": "Addressing the Spread of Trust and Distrust in Distributed Human-AI Teaming Constellations", "author": "Beau G Schelble, Christopher Flathmann, Matthew Scalia, Shiwen Zhou, Christopher Myers, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:8AbLer7MMksC", "abstract": "OBJECTIVE: >As autonomous systems mature, the applied industry has begun adopting the technology. Many of these applications include the creation of human-artificial intelligence (AI) teams, which promise to increase the already known advantages of working in team environments. The efficacy of the AI agents that make up these teams has always been a significant focus. However, a shift from technical ability to social abilities has occurred. A newfound emphasis on trust within these human-AI teams has prompted research on supporting trust between humans and AI teammates, how AI affects trust between the humans within the team, and how team composition (majority AI versus majority human) influences trust development. Even the efficacy of trust repair strategies, adapted from human-automation interaction, is being explored in human-AI teaming. In the current paper, we examine an essential component of trust that\u00a0\u2026", "issued": {"date-parts":[[2022]]}},
{"title": "Examining the impact of varying levels of AI teammate influence on human-AI teams", "author": "Christopher Flathmann, Beau G Schelble, Patrick J Rosopa, Nathan J McNeese, Rohit Mallick", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:AXPGKjj_ei8C", "abstract": "OBJECTIVE: >The implementation of AI teammates is creating a wealth of research that examines how AI teammates impact human-AI teams. However, AI teammates themselves are not static, and their roles and responsibilities in human-AI teams are likely to change as technologies advance in the coming years. As a result of this advancement, AI teammates will gain influence in teams, which refers to their ability to change and manipulate a team\u2019s shared resources. This study uses a mixed-methods experiment to examine how the amount of influence AI teammates have on a team\u2019s shared resources can impact the team outcomes of human teammate performance, teammate perceptions, and whole-team perception. Results indicate that AI teammates that increase their influence on shared resources over time can stagnate the improvement of human performance, but AI teammates that decrease their influence on shared\u00a0\u2026", "issued": "2023/9/1"},
{"title": "Knowing Unknown Teammates: Exploring Anonymity and Explanations in a Teammate Information-Sharing Recommender System", "author": "Geoff Musick, Elizabeth S Gilman, Wen Duan, Nathan J McNeese, Bart Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:5awf1xo2G04C", "abstract": "OBJECTIVE: >A growing organizational trend is to utilize ad-hoc team formation which allows for teams to intentionally form based on the member skills required to accomplish a specific task. Due to the unfamiliar nature of these teams, teammates are often limited by their understanding of one another (e.g., teammate preferences, tendencies, attitudes) which limits the team's functioning and efficiency. This study conceptualizes and investigates the use of a teammate information-sharing recommender system which selectively shares interpersonal recommendations between unfamiliar teammates (e.g., \"Your voice may be overshadowed by this teammate when making decisions...\") to promote teammate understanding. Through a mixed-methods approach involving 105 participants working on actual unfamiliar teams, this study explores how presentation elements such as anonymity and explanations influence system perceptions\u00a0\u2026", "issued": "2023/10/4"},
{"title": "Development of a Real-Time Trust/Distrust Metric Using Interactive Hybrid Cognitive Task Analysis", "author": "Shiwen Zhou, Xioyun Yin, Matthew J Scalia, Ruihao Zhang, Jamie C Gorman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:VL0QpB8kHFEC", "abstract": "OBJECTIVE: >While there is increased interest in how trust spreads in Human Autonomy Teams (HATs), most trust measurements are subjective and do not examine real-time changes in trust. To develop a trust metric that consists of objective variables influenced by trust/distrust manipulations, we conducted an Interactive hybrid Cognitive Task Analysis (IhCTA) for a Remotely Piloted Aerial System (RPAS) HAT. The IhCTA adapted parts of the hybrid Cognitive Task Analysis (hCTA) framework. In this paper, we present the four steps of the IhCTA approach, including 1) generating a scenario task overview, 2) generating teammate-specific event flow diagrams, 3) identifying interactions and interdependencies impacted by trust/distrust manipulations, and 4) processing RPAS variables based on the IhCTA to create a metric. We demonstrate the application of the metric through a case study that examines how the influence of specific\u00a0\u2026", "issued": "2023/9"},
{"title": "Invoking principles of groupware to develop and evaluate present and future human-agent teams", "author": "Christopher Flathmann, Beau Schelble, Brock Tubre, Nathan McNeese, Paige Rodeghero", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:dfsIfKJdRG4C", "abstract": "OBJECTIVE: >Advances in artificial intelligence are constantly increasing its validity as a team member enabling it to effectively work alongside humans and other artificial teammates. Unfortunately, the digital nature of artificial teammates and their restrictive communication and coordination requirements complicate the interaction patterns that exist. In light of this challenge, we create a theoretical framework that details the possible interactions in human-agent teams, emphasizing interactions through groupware, which is based on literature regarding groupware and human-agent teamwork. As artificial intelligence changes and advances, the interaction in human-agent teams will also advance, meaning interaction frameworks and groupware must adapt to these changes. We provide examples and a discussion of the frameworks ability to adapt based on advancements in relevant research areas like natural language processing\u00a0\u2026", "issued": "2020/11/10"},
{"title": "Leveraging Artificial Intelligence for Team Cognition in Human-AI Teams", "author": "Beau Gregory Schelble, Nathan McNeese, Guo Freeman, Bart Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:_Ybze24A_UAC", "abstract": "OBJECTIVE: >Advances in artificial intelligence (AI) technologies have enabled AI to be applied across a wide variety of new fields like cryptography, art, and data analysis. Several of these fields are social in nature, including decision-making and teaming, which introduces a new set of challenges for AI research. While each of these fields has its unique challenges, the area of human-AI teaming is beset with many that center around the expectations and abilities of AI teammates. One such challenge is understanding team cognition in these human-AI teams and AI teammates\u2019 ability to contribute towards, support, and encourage it. Team cognition is defined as any cognitive activity among the team members regarding their shared knowledge of the team and task, including concepts such as shared task or team mental models, team situation awareness, or schema similarity. Team cognition is fundamental to effective teams, as it is\u00a0\u2026", "issued": "2023/12"},
{"title": "Stepping out of the shadow of human-human teaming: Crafting a unique identity for human-autonomy teams", "author": "Nathan J McNeese, Christopher Flathmann, Eduardo Salas", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:9vf0nzSNQJEC", "abstract": "OBJECTIVE: >While the rapid expansion of human-autonomy teaming can and should be aided by using historically beneficial theories from human-human teams, the advent of human-autonomy teaming should also possess a unique identity that explicitly denotes the specific advantages, limitations, and considerations these teams will present to society. As such, continuing to frame human-autonomy teams as technologically advanced human-human teams might not only restrict the global effectiveness of these teams but doing so might also stagnate these teams from being well perceived and respected by humans. However, recent efforts to differentiate human-autonomy teams have prioritized the differentiation from human-autonomy interactions rather than human-human teams. The following article further differentiates human-autonomy teams from human-human teams by first discussing the core differentiating\u00a0\u2026", "issued": "2023/11/1"},
{"title": "Human factors considerations for the context-aware design of adaptive autonomous teammates", "author": "Allyson I Hauptman, Rohit Mallick, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:fEOibwPWpKIC", "abstract": "OBJECTIVE: >Despite the gains in performance that AI can bring to human-AI teams, they also present them with new challenges, such as the decline in human ability to respond to AI failures as the AI becomes more autonomous. This challenge is particularly dangerous in human-AI teams, where the AI holds a unique role in the team\u2019s success. Thus, it is imperative that researchers find solutions for designing AI team-mates that consider their human team-mates\u2019 needs in their adaptation logic. This study explores adaptive autonomy as a solution to overcoming these challenges. We conducted twelve contextual inquiries with professionals in two teaming contexts in order to understand how human teammate perceptions can be used to determine optimal autonomy levels for AI team-mates. The results of this study will enable the human factors community to develop AI team-mates that can enhance their team\u2019s performance while\u00a0\u2026", "issued": "2024/7/25"},
{"title": "Leveling up teamwork in esports: Understanding team cognition in a dynamic virtual environment", "author": "Geoff Musick, Rui Zhang, Nathan J McNeese, Guo Freeman, Anurata Prabha Hridi", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:NhqRSupF_l8C", "abstract": "OBJECTIVE: >A large body of research has underscored the importance of the cognitive process of team cognition and its relation to team performance. However, little research has focused on applying such an important teamwork process to computer-mediated collaboration within a fast-paced virtual environment. In this paper, we use esports as a research platform to address this limitation due to its fast-paced nature and its heavy reliance on teamwork. We report the experience and perceptions of 20 players with regard to their descriptions of team cognition within esports. We found that esports players relied on their game experience and understanding of role interdependencies in order to develop team cognition with strangers. We also found that experienced teams utilized a mutual understanding of teammate skills and personalities in order to predict responses and limit the verbal communication required to make quick team\u00a0\u2026", "issued": "2021/4/22"},
{"title": "Channeling End-User Creativity: Leveraging Live Streaming for Distributed Collaboration in Indie Game Development", "author": "Li, Guo Freeman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:eJXPG6dFmWUC", "abstract": "OBJECTIVE: >This paper explores the role of live streaming in distributed collaborative software development using indie game development, an end-user driven creative community, as an example. We conducted 27 in-depth interviews with indie game developers from various cultures and countries, who had engaged in live streaming for collaborative software development either as a streamer or a viewer. Our findings show how live streaming can be used by indie game developers to support their endeavors to innovate the traditional game development model, which goes beyond just learning and teaching technical skills. We also highlight the potential challenges indie developers face in this process. We thus make unique contributions to CSCW by bridging the previously often disconnected research agendas on collaborative software development and live streaming. We also provide potential directions for designing future\u00a0\u2026", "issued": "2022/11/11"},
{"title": "Fostering human-agent team leadership by leveraging human teaming principles", "author": "Christopher Flathmann, Beau G Schelble, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:WbkHhVStYXYC", "abstract": "OBJECTIVE: >With human-agent teams beginning to enter the workforce, it is important that humans are well equipped to lead their future teams. Due to the addition of artificial intelligence to teams, the behavioral functions of leaders need to be critically examined to determine their fit with the future of human-agent teamwork. This paper identifies these functional behaviors as resource management behaviors and information behaviors based on past research in teamwork. These behaviors are reviewed within the context of human-human teamwork to define human-oriented leadership behaviors. Based on the review of humanhuman teamwork along with recent research in human-agent teamwork, an adaptable framework is created for leadership behaviors that will help guide human leaders in human-agent teams. This framework provides a foundation for future human-agent teams to empower and guide human leaders of\u00a0\u2026", "issued": "2021/9/8"},
{"title": "Understanding the influence of AI autonomy on AI explainability levels in human-AI teams using a mixed methods approach", "author": "Allyson I Hauptman, Beau G Schelble, Wen Duan, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:tzM49s52ZIMC", "abstract": "OBJECTIVE: >An obstacle to effective teaming between humans and AI is the agent\u2019s\" black box\" design. AI explanations have proven benefits, but few studies have explored the effects that explanations can have in a teaming environment with AI agents operating at heightened levels of autonomy. We conducted two complementary studies, an experiment and participatory design sessions, investigating the effect that varying levels of AI explainability and AI autonomy have on the participants\u2019 perceived trust and competence of an AI teammate to address this research gap. The results of the experiment were counter-intuitive, where the participants actually perceived the lower explainability agent as both more trustworthy and more competent. The participatory design sessions further revealed how a team\u2019s need to know influences when and what teammates need explained from AI teammates. Based on these findings, several\u00a0\u2026", "issued": "2024/5/18"},
{"title": "Communication in Human-AI Teaming", "author": "Wen Duan, Nathan McNeese, Rui Zhang", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:N5tVd3kTz84C", "abstract": "OBJECTIVE: >This chapter reviews empirical research on the role of communication in human-AI teaming. Specifically, it introduces and categorizes the communication behaviors commonly investigated in HAT research, such as anticipatory information pushing, transparency, and explainable AI, as well as verbal anthropomorphism. It reviews findings on how these communication behaviors impact various team processes and outcomes, such as team performance, situation awareness, and trust.", "issued": {"date-parts":[[2023]]}},
{"title": "Team situation awareness and conflict: A study of human\u2013machine teaming", "author": "Nathan J McNeese, Mustafa Demir, Nancy J Cooke, Manrong She", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:dshw04ExmUIC", "abstract": "OBJECTIVE: >This article focuses on two fundamental human\u2013human teamwork behaviors and seeks to understand them better in human\u2013machine teams. Specifically, team situation awareness (TSA) and team conflict are examined in human\u2013machine teams. There is a significant need to identify how TSA and team conflict occur during human\u2013machine teaming, in addition to how they impact each other. In this work, we present an experiment aimed at understanding TSA and team conflict in the context of human\u2013machine teaming in a remotely piloted aircraft system (RPAS). Three conditions were tested: (1) <i>control</i>: teams consisted of all humans; (2) <i>synthetic</i>: teams consisted of the pilot role being occupied by a computational agent based on ACT-R architecture that employed AI capabilities, with all other team roles being humans; and (3) <i>experimenter</i>: an experimenter playing the role of the pilot as a highly effective\u00a0\u2026", "issued": "2021/9"},
{"title": "Stable teamwork marriages in healthcare: Applying machine learning to surgeon-nurse-patient matching", "author": "Lorenzo Barberis Canonico, Nathan J McNeese, Marissa L Shuffler", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:bEWYMUwI8FkC", "abstract": "OBJECTIVE: >Hospitals are plagued with a multitude of logistical challenges amplified by a time-sensitive and high intensity environment. These conditions have resulted in burnout among both doctors and nurses as they work tirelessly to provide critical care to patients in need. We propose a new machine-learning-powered matching mechanism that manages the surgeon-nurse-patient assignment process in an efficient way that saves time and energy for hospitals, enabling them to focus almost entirely on delivering effective care. Through this design, we show how incorporating artificial intelligence into management systems enables teams of all sizes to meaningfully coordinate in highly chaotic and complex environments.", "issued": "2018/9"},
{"title": " Pro-Amateur-Driven Technological Innovation: Participation and Challenges in Indie Game Development", "author": "Guo Freeman, Nathan McNeese, Jeffrey Bardzell, Jeffrey Bardzell", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:M05iB0D1s5AC", "abstract": "OBJECTIVE: >The phenomenon of end-user driven technological practices such as DIY making, hacking, crafting, and open design/manufacturing is shaping debates in HCI and CSCW about participatory innovation dynamics. However, prior research also reveals two limitations, namely, unequal participation in decision-making and the neglect of middle-tier \"pro-amateur\" end users. In this paper, we use independent [indie] game development as a case to explore the above-mentioned two key issues. Specifically, we highlight the importance of small teams, \"crafting,\" and \"democracy\" in supporting and facilitating middle-tier end-users' engagement with technology. Our focus on indie game developers, an understudied group of middle-tier end users in HCI and CSCW, offers new empirical evidence of the dynamic process through which pro-amateurs can participate in technological innovation. Understanding their practices and\u00a0\u2026", "issued": "2020/1/4"},
{"title": "Investigating AI teammate communication strategies and their impact in human-AI teams for effective teamwork", "author": "Rui Zhang, Wen Duan, Christopher Flathmann, Nathan McNeese, Guo Freeman, Alyssa Williams", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:WqliGbK-hY8C", "abstract": "OBJECTIVE: >Recently, AI is integrating into teams to collaborate with humans as a teammate with the goal of achieving unprecedented team outcomes. Much of the coordination between humans and AI teammates relies on human-AI communication, which is challenging due to AI's limitations on natural language communication. Thus, it is essential to identify and develop effective communication strategies for AI teammates in human-AI teams to facilitate the coordination process. Through interviews with 60 participants who collaborated with an AI teammate in a multiplayer online game, in this paper, we explore communication strategies that humans expect AI teammates to apply to support human-AI coordination and collaboration in dyadic teaming environments, and how the AI teammate's communication can impact teaming processes. Our findings highlight four communication strategies AI teammates should apply to support\u00a0\u2026", "issued": "2023/10/4"},
{"title": "I Know This Looks Bad, But I Can Explain: Understanding When AI Should Explain Actions In Human-AI Teams", "author": "Rui Zhang, Christopher Flathmann, Geoff Musick, Beau Schelble, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:UHK10RUVsp4C", "abstract": "OBJECTIVE: >Explanation of artificial intelligence (AI) decision-making has become an important research area in human\u2013computer interaction (HCI) and computer-supported teamwork research. While plenty of research has investigated AI explanations with an intent to improve AI transparency and human trust in AI, how AI explanations function in teaming environments remains unclear. Given that a major benefit of AI giving explanations is to increase human trust understanding how AI explanations impact human trust is crucial to effective human-AI teamwork. An online experiment was conducted with 156 participants to explore this question by examining how a teammate\u2019s explanations impact the perceived trust of the teammate and the effectiveness of the team and how these impacts vary based on whether the teammate is a human or an AI. This study shows that explanations facilitate trust in AI teammates when explaining\u00a0\u2026", "issued": "2024/2/5"},
{"title": "A Tale of Creativity and Struggles: Team Practices for Bottom-Up Innovation in Virtual Game Jams", "author": "Guo Freeman, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:xtRiw3GOFMkC", "abstract": "OBJECTIVE: >Game jams are intense and time-sensitive online or face-to-face game creation events where a digital game is developed in a relatively short time frame (typically 48 to 72 hours) exploring given design constraints and end results are shared publicly. They have increasingly become emerging sites where non-professional game developers, amateurs, and hobbyists engage in bottom-up technological innovation by collaboratively designing and developing more creative and novel digital products. Drawing on 28 interviews, in this paper we focus on how game developers collaborate as small teams to innovate game design and development from the bottom up in virtual game jams (i.e., exclusively online) and the unique role of virtual game jams in their technological innovation. We contribute to CSCW by providing new empirical evidence of how team practices for innovation may emerge in a novel technology\u00a0\u2026", "issued": "2021/4/22"},
{"title": "The pursuit of happiness: the power and influence of AI teammate emotion in human-AI teamwork", "author": "Rohit Mallick, Christopher Flathmann, Caitlin Lancaster, Allyson Hauptman, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=20&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:1yQoGdGgb4wC", "abstract": "OBJECTIVE: >As the world evolves, human-AI teams (HAT) have become increasingly more capable in their ability to complete task objectives. Due to this rising importance, it has become essential to understand the interpersonal dynamism between humans and AI to further optimise their performance potential. Given the demonstrated utility of emotional communication within human-human team structures, this research investigates the nature of AI-sourced positive emotions on human teammates. Through 47 interviews, our findings show that for these AI teammates to be accepted, human teammates have preferences on understanding the emotional utility prior to its presentation, as well as which emotions are situationally acceptable. Also, findings show that integrating emotions within AI teammates has a positive influence on human perceptions and behaviour in a task. In further detail, emotions act as status updates that\u00a0\u2026", "issued": "2023/11/9"},
{"title": "Human-AI teams in complex military operations: Soldiers\u2019 perception of intelligent AI agents as teammates in human-AI teams", "author": "Sarvesh Sawant, Camden Brady, Rohit Mallick, Nathan McNeese, Kapil Chalil Madathil, Jeffrey Bertrand", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:ye4kPcJQO24C", "abstract": "OBJECTIVE: >Military decision-making frequently involves complex problems in non-routine situations with minimal rule-based or automated solutions. As human information processing capabilities are limited, processing the required scale of information increases the decision-makers\u2019 workload, impacting their situational awareness and affecting the quality of soldiers\u2019 decisions. This study uses a route clearance task as a use-case scenario to understand the issues in team-level decision-making in military tasks, the challenges in successfully completing the mission, and the demands placed on AI teammates when working in a human-AI team. We interviewed eight subject matter experts with prior experience in route clearance operations. The themes generated by analyzing the interview transcripts provide insights into soldiers\u2019 perceptions of AI teammates as well as recommendations for successfully integrating human-AI\u00a0\u2026", "issued": "2023/9"},
{"title": "Collaborative augmented reality in higher education: A systematic review of effectiveness, outcomes, and challenges", "author": "Bhargav Upadhyay, Camden Brady, Kapil Chalil Madathil, Jeffrey Bertrand, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:j8SEvjWlNXcC", "abstract": "OBJECTIVE: >This article reports a systematic literature review that examined past research exploring the effectiveness of collaborative Augmented Reality (AR) enabled instruction, in higher education contexts. To be included, an article should consist of an experimental study investigating the use of collaborative AR for learning in higher education settings. An initial search was conducted on five databases that resulted in a total of 2537 articles, of which 20 were finalized for this review. The main findings suggest that AR-enabled collaborative learning benefits students\u2019 overall learning outcomes and provides a positive collaboration experience in higher education settings. Further research is needed to determine the interaction elements, collaboration mechanisms, and information representation through AR that would potentially enhance student learning outcomes. This article concludes by discussing the implications of these\u00a0\u2026", "issued": "2024/11/1"},
{"title": "An exploratory study investigating the barriers, facilitators, and demands affecting caregivers in a telemedicine integrated ambulance-based setting for stroke care", "author": "Hunter Rogers, Kapil Chalil Madathil, Anjali Joseph, Christine Holmstedt, Suparna Qanungo, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:OU6Ihb5iCvQC", "abstract": "OBJECTIVE: >Telemedicine implementation in ambulances can reduce time to treatment for stroke patients, which is important as \u201ctime is brain\u201d for these patients. Limited research has explored the demands placed on acute stroke caregivers in a telemedicine-integrated ambulance system. This study investigates the impact of telemedicine on workload, teamwork, workflow, and communication of geographically distributed caregivers delivering stroke care in ambulance-based telemedicine and usability of the system. Simulated stroke sessions were conducted with 27 caregivers, who subsequently completed a survey measuring workload, usability, and teamwork. Follow-up interviews with each caregiver ascertained how telemedicine affected workflow and demands which were analyzed for barriers and facilitators to using telemedicine. Caregivers experienced moderate workload and rated team effectiveness and usability high\u00a0\u2026", "issued": "2021/11/1"},
{"title": "The components of trust for collaborating with ai colleagues", "author": "Allyson I Hauptman, Wen Duan, Nathan J Mcneese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=50&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:kRWSkSYxWN8C", "abstract": "OBJECTIVE: > AI technologies are capable of improving the performance and productivity of teams in a variety of work contexts. These advantages may be optimized when the AI agent is considered a full team member. A vital component of the agent\u2019s acceptance as a team member or colleague is the degree to which its human coworkers feel they can trust it. To explore what factors affect the perceptions of an AI agent as a trustworthy team member and a legitimate colleague, we interviewed twenty-two professionals representing various work roles. Our results revealed that the following qualities contribute to professionals\u2019 trust in AI as a colleague: a visual presence reflective of coworkers, engagement in feedback loop and team processes through human communication, and the ability for self-development. These findings contribute to the CSCW community by advancing the current understanding of human-AI teaming and\u00a0\u2026", "issued": "2022/11/8"},
{"title": "To Share or Not to Share: Understanding and Modeling Individual Disclosure Preferences in Recommender Systems for the Workplace", "author": "Geoff Musick, Wen Duan, Shabnam Najafian, Subhasree Sengupta, Christopher Flathmann, Bart Knijnenburg", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:W5xh706n7nkC", "abstract": "OBJECTIVE: >Newly-formed teams often encounter the challenge of members coming together to collaborate on a project without prior knowledge of each other's working and communication styles. This lack of familiarity can lead to conflicts and misunderstandings, hindering effective teamwork. Derived from research in social recommender systems, team recommender systems have shown the ability to address this challenge by providing personality- derived recommendations that help individuals interact with teammates with differing personalities. However, such an approach raises privacy concerns as to whether teammates would be willing to disclose such personal information with their team. Using a vignette survey conducted via a research platform that hosts a team recommender system, this study found that context and individual differences significantly impact disclosure preferences related to team recommender\u00a0\u2026", "issued": "2024/2/21"},
{"title": "Human\u2013autonomy teaming: A review and analysis of the empirical literature", "author": "Thomas O\u2019Neill, Nathan McNeese, Amy Barron, Beau Schelble", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:4OULZ7Gr8RgC", "abstract": "OBJECTIVE: >We define human\u2013autonomy teaming and offer a synthesis of the existing empirical research on the topic. Specifically, we identify the research environments, dependent variables, themes representing the key findings, and critical future research directions.BACKGROUND: >Whereas a burgeoning literature on high-performance teamwork identifies the factors critical to success, much less is known about how human\u2013autonomy teams (HATs) achieve success. Human\u2013autonomy teamwork involves humans working interdependently toward a common goal along with autonomous agents. Autonomous agents involve a degree of self-government and self-directed behavior (agency), and autonomous agents take on a unique role or set of tasks and work interdependently with human team members to achieve a shared objective.METHODS: >We searched the literature on human\u2013autonomy teaming. To meet our criteria for\u00a0\u2026", "issued": "2022/8"},
{"title": "LLM-based Smart Reply (LSR): Enhancing Collaborative Performance with ChatGPT-mediated Smart Reply System", "author": "Ashish Bastola, Hao Wang, Judsen Hembree, Pooja Yadav, Nathan McNeese, Abolfazl Razi", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:ZfRJV9d4-WMC", "abstract": "OBJECTIVE: >Interactive user interfaces have increasingly explored AI\u2019s role in enhancing communication efficiency and productivity in collaborative tasks. The emergence of Large Language Models (LLMs) such as ChatGPT has revolutionized conversational agents, employing advanced deep learning techniques to generate context-aware, coherent, and personalized responses. Consequently, LLM-based AI assistants provide a more natural and efficient user experience across various scenarios. In this paper, we study how LLM models can be used to improve work efficiency in collaborative workplaces. Specifically, we present an LLM-based Smart Reply (LSR) system utilizing the ChatGPT to generate personalized responses in professional collaborative scenarios while adapting to context and communication style based on prior responses. Our two-step process involves generating a preliminary response type (eg, Agree, Disagree) to provide a generalized direction for message generation, thus reducing response drafting time. We conducted an experiment where participants completed simulated work tasks involving a Dual N-back test and subtask scheduling through Google Calendar while interacting with co-workers. Our findings indicate that the proposed LSR reduces overall workload, as measured by the NASA TLX, and improves work performance and productivity in the N-back task. We also provide qualitative analysis based on participants\u2019 experiences, as well as design considerations to provide future directions for improving such implementations.", "issued": "2023/6"},
{"title": "Can We Build it? Yes, We Can! Development Procedure of High-Fidelity Simulation Environments for Human-Agent Teams", "author": "Rohit Mallick, Sarvesh Sawant, Camden Brady, Nathan McNeese, Kapil Chalil Madathil, Jeff Bertrand", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:LjlpjdlvIbIC", "abstract": "OBJECTIVE: >This paper presents a bottom-up approach to designing and developing a high-fidelity simulation environment that fosters human acceptance of artificial intelligence (AI) as teammates by refining their mental models of appropriate teamwork expectations. Our process begins by first identifying an appropriate contextual situation that warrants humans teaming with AI as opposed to other team-based configurations. Those criteria are based on the delegation of roles appropriate to the established strengths of humans/AI, as well as the interdependence created between those roles to accentuate the expectations of teammate behavior. Next, qualitative interviews should be conducted with diverse subject matter experts to gain a comprehensive understanding of the situation and the environmental attributes through various perspectives. Once analyzed using thematic analysis, themes present themselves as design\u00a0\u2026", "issued": "2023/9"},
{"title": "The Pursuit of Transdisciplinary Research: Eight Recommendations for Integrating Disciplines", "author": "Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:NaGl4SEjCO4C", "abstract": "OBJECTIVE: >Significant strides are being made to produce more transdisciplinary research in the systems, man, and cybernetics (SMC) community, which is inherently interdisciplinary. To produce effective transdisciplinary SMC work, perspectives from multiple disciplines must be integrated. Yet, continued work is still needed to help promote the transdisciplinary nature of SMC and encourage more transdisciplinary work in this area. This article offers eight recommendations for developing foundational transdisciplinary SMC-based research. These recommendations relate to the following areas: 1) academic training, 2) a shared and common language, 3) the need for transdisciplinarity, 4) problem space requirements, 5) shared spaces and mechanisms, 6) team science and cognition, 7) credit, and 8) metrics to measure transdisciplinary performance.", "issued": "2019/10/14"},
{"title": "What Happens When Humans Believe Their Teammate is an AI? An Investigation into Humans Teaming with Autonomy", "author": "Geoff Musick, Tom O\u2019Neill, Beau Schelble, Nathan McNeese, Jonn Henke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=80&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:CHSYGLWDkRkC", "abstract": "OBJECTIVE: >As artificial intelligence (AI) continues to grow in proficiency, the potential for AI to be used as team members rather than tools is becoming closer to realization. This advancement is driving new research investigations into the applicability of human-human teamwork knowledge to the context of human-autonomy teaming. In the current study, we apply qualitative methods to explore how the perceived composition of a team (how many humans and how many agents on the team) affects sentiments toward teammates, team processes, cognitive states, and the emergence of a system of team cognition. A total of 46 teams completed a teamwork simulation task and were interviewed afterwards regarding their teamwork experience. All of the teams were comprised of only humans; however, two conditions were led to believe that their teammate(s) were autonomous agents. Interviews were analyzed using grounded theory\u00a0\u2026", "issued": "2021/5/4"},
{"title": "Team synchrony in human-autonomy teaming", "author": "Mustafa Demir, Nathan J McNeese, Nancy J Cooke", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:_Qo2XoVZTnwC", "abstract": "OBJECTIVE: > In Human-Autonomy Teaming (HAT), the development of a highly autonomous agent as a team member is difficult. Similar to human-human teaming, there are multiple dimensions of social behaviors that occur during HAT that must be accounted for within the development of the agent or system. One of these dimensions is team synchrony. In general, team synchrony is, when two systems (or two individuals in a team) are synchronized, resulting in their recurrences being dependent on each other. In order for a human-autonomy team to be synchronous the agent must communicate effectively (i.e., synchronize effectively) with its human team members. Thus, in this paper we present a conceptual discussion on what team synchrony is, how it occurs, and how to better develop it in HAT. To ground our discussion, we use our recent studies in which we empirically looked at team behaviors and team synchrony\u00a0\u2026", "issued": {"date-parts":[[2018]]}},
{"title": "Exploration of teammate trust and interaction dynamics in human-autonomy teaming", "author": "Mustafa Demir, Nathan J McNeese, Jaime C Gorman, Nancy J Cooke, Christopher W Myers, David A Grimm", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=70&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:EUQCXRtRnyEC", "abstract": "OBJECTIVE: >This article considers human-autonomy teams (HATs) in which two human team members interact and collaborate with an autonomous teammate to achieve a common task while dealing with unexpected technological failures that were imposed either in automation or autonomy. A Wizard of Oz methodology is used to simulate the autonomous teammate. One of the critical aspects of HAT performance is the trust that develops over time as team members interact with each other in a dynamic task environment. For this reason, it is important to examine the dynamic nature of teammate trust through real-time measures of team interactions. This article examines team interaction and trust to understand better how they change under automation and autonomy failures. Thus, we address two research questions: 1) How does trust in HATs evolve over time?; and 2) How is the relationship between team interaction and trust\u00a0\u2026", "issued": "2021/10/7"},
{"title": "Both Sides of the Story: Changing the Pre-Existing Culture of Dread Surrounding Student Teamwork in Breakout Rooms", "author": "Makayla Moster, Ella Kokinda, Paige Rodeghero, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=40&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:t6usbXjVLHcC", "abstract": "OBJECTIVE: >As universities transitioned in-person classrooms to virtual classrooms, instructors faced challenges and changes in how they conduct their classes and teaching style trying to keep virtual classrooms as similar to in-person as much as possible through the use of group work in breakout sessions. Within these breakout sessions, students are expected to work together to complete an assignment. Through 669 surveys and 19 interviews, our paper outlines the successes and challenges of breakout sessions and teamwork in virtual learning environments faced by professors, graduate teaching assistants, and students. Our findings show the importance of pedagogical research for online environments, the student need for persistent instructions and check-ins to facilitate teamwork in breakout sessions, and strong justification for the use of breakout sessions in online courses. Based on our findings, we propose design\u00a0\u2026", "issued": "2023/4/16"},
{"title": "The wisdom of the market: Using human factors to design prediction markets for collective intelligence", "author": "Lorenzo Barberis Canonico, Christopher Flathmann, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=100&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:vV6vV6tmYwMC", "abstract": "OBJECTIVE: >There is an ever-growing literature on the power of prediction markets to harness \u201cthe wisdom of the crowd\u201d from large groups of people. However, traditional prediction markets are not designed in a human-centered way, often restricting their own potential. This creates the opportunity to implement a cognitive science perspective on how to enhance the collective intelligence of the participants. Thus, we propose a new model for prediction markets that integrates human factors, cognitive science, game theory and machine learning to maximize collective intelligence. We do this by first identifying the connections between prediction markets and collective intelligence, to then use human factors techniques to analyze our design, culminating in the practical ways with which our design enables artificial intelligence to complement human intelligence.", "issued": "2019/11"},
{"title": "Machine learning as grounded theory: Human-centered interfaces for social network research through artificial intelligence", "author": "Lorenzo Barberis Canonico, Nathan J McNeese, Chris Duncan", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=120&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:TFP_iSt0sucC", "abstract": "OBJECTIVE: >Internet technologies have created unprecedented opportunities for people to come together and through their collective effort generate large amounts of data about human behavior. With the increased popularity of grounded theory, many researchers have sought to use ever-increasingly large datasets to analyze and draw patterns about social dynamics. However, the data is simply too big to enable a single human to derive effective models for many complex social phenomena. Computational methods offer a unique opportunity to analyze a wide spectrum of sociological events by leveraging the power of artificial intelligence. Within the human factors community, machine learning has emerged as the dominant AI-approach to deal with big data. However, along with its many benefits, machine learning has introduced a unique challenge: interpretability. The models of macro-social behavior generated by AI are so\u00a0\u2026", "issued": "2018/9"},
{"title": "Human-AI partnerships for chaos engineering", "author": "Lorenzo Barberis Canonico, Vimal Vakeel, James Dominic, Paige Rodeghero, Nathan McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=90&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:abG-DnoFyZgC", "abstract": "OBJECTIVE: >Chaos Engineering refers to the practice of introducing faults in a system and observe the extent to which the system remains fault tolerant. However, is randomization the best approach to expose faults within a system? We aim to answer this question by introducing Chaos into different software architecture patterns and demonstrate how a back-end system can be made fault tolerant through artificial intelligence (AT). This paper discusses what aspects of AI would be used to make a system more resilient to perturbations and the results of these findings against existing chaos engineering approaches.", "issued": "2020/6/27"},
{"title": "Autonomous intelligent agents for team training", "author": "Christopher Myers, Jerry Ball, Nancy Cooke, Mary Freiman, Michelle Caisse, Stuart Rodgers, Mustafa Demir", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=110&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:M3NEmzRMIkIC", "abstract": "OBJECTIVE: >The rise in autonomous system research and development combined with the maturation of computational cognitive architectures holds the promise of high-cognitive-fidelity agents capable of operating as team members for training. We report an ACT-R model capable of operating as a team member within a remotely piloted aerial system, and provide results from a first-of-its-kind controlled, randomized empirical evaluation in which teams that worked with an AST were compared against all-human teams. Our results demonstrate that ASTs can be incorporated into human teams, providing training opportunities when teammates are unavailable. We conclude with issues faced in developing ASTs and lessons learned for future and current developers.", "issued": "2018/12/13"},
];
