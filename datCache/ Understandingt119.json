{"title": "Understanding the influence of AI autonomy on AI explainability levels in human-AI teams using a mixed methods approach", "author": "Allyson I Hauptman, Beau G Schelble, Wen Duan, Christopher Flathmann, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:tzM49s52ZIMC", "abstract": "OBJECTIVE: >An obstacle to effective teaming between humans and AI is the agent\u2019s\" black box\" design. AI explanations have proven benefits, but few studies have explored the effects that explanations can have in a teaming environment with AI agents operating at heightened levels of autonomy. We conducted two complementary studies, an experiment and participatory design sessions, investigating the effect that varying levels of AI explainability and AI autonomy have on the participants\u2019 perceived trust and competence of an AI teammate to address this research gap. The results of the experiment were counter-intuitive, where the participants actually perceived the lower explainability agent as both more trustworthy and more competent. The participatory design sessions further revealed how a team\u2019s need to know influences when and what teammates need explained from AI teammates. Based on these findings, several\u00a0\u2026", "issued": "2024/5/18"}