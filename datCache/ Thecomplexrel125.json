{"title": "The complex relationship of AI ethics and trust in human\u2013AI teaming: insights from advanced real-world subject matter experts", "author": "Jeremy Lopez, Claire Textor, Caitlin Lancaster, Beau Schelble, Guo Freeman, Rui Zhang", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=30&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:dTyEYWd-f8wC", "abstract": "OBJECTIVE: >Human-autonomy teams will likely first see use within environments with ethical considerations (e.g., military, healthcare). Therefore, we must consider how to best design an ethical autonomous teammate that can promote trust within teams, an antecedent to team effectiveness. In the current study, we conducted 14 semi-structured interviews with US Air Force pilots on the topics of autonomous teammates, trust, and ethics. A thematic analysis revealed that the pilots see themselves serving a parental role alongside a developing machine teammate. As parents, the pilots would feel responsible for their machine teammate\u2019s behavior, and their unethical actions may not lead to a loss of trust. However, once the pilots feel their teammate has matured, their unethical actions would likely lower trust. To repair that trust, the pilots would want to understand their teammate\u2019s processing, yet they are concerned about their\u00a0\u2026", "issued": "2023/7/5"}