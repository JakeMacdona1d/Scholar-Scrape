{"title": "Language, Camera, Autonomy! Prompt-engineered Robot Control for Rapidly Evolving Deployment", "author": "Jacob P Macdonald, Rohit Mallick, Allan B Wollaber, Jaime D Pe\u00f1a, Nathan McNeese, Ho Chit Siu", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=10&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:Fu2w8maKXqMC", "abstract": "OBJECTIVE: >The Context-observant LLM-Enabled Autonomous Robots (CLEAR) platform offers a general solution for large language model (LLM)-enabled robot autonomy. CLEAR-controlled robots use natural language to perceive and interact with their environment: contextual description deriving from computer vision and optional human commands prompt intelligent LLM responses that map to robotic actions. By emphasizing prompting, system behavior is programmed without manipulating code, and unlike other LLM-based robot control methods, we do not perform any model fine-tuning. CLEAR employs off-the-shelf pre-trained machine learning models for controlling robots ranging from simulated quadcopters to terrestrial quadrupeds. We provide the open-source CLEAR platform, along with sample implementations for a Unity-based quadcopter and Boston Dynamics Spot\u00ae robot. Each LLM used, GPT-3.5, GPT-4, and\u00a0\u2026", "issued": "2024/3/11"}