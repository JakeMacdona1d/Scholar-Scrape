{"title": "Addressing the Spread of Trust and Distrust in Distributed Human-AI Teaming Constellations", "author": "Beau G Schelble, Christopher Flathmann, Matthew Scalia, Shiwen Zhou, Christopher Myers, Nathan J McNeese", "URL": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=G1CnZ38AAAAJ&cstart=60&pagesize=10&sortby=pubdate&citation_for_view=G1CnZ38AAAAJ:8AbLer7MMksC", "abstract": "OBJECTIVE: >As autonomous systems mature, the applied industry has begun adopting the technology. Many of these applications include the creation of human-artificial intelligence (AI) teams, which promise to increase the already known advantages of working in team environments. The efficacy of the AI agents that make up these teams has always been a significant focus. However, a shift from technical ability to social abilities has occurred. A newfound emphasis on trust within these human-AI teams has prompted research on supporting trust between humans and AI teammates, how AI affects trust between the humans within the team, and how team composition (majority AI versus majority human) influences trust development. Even the efficacy of trust repair strategies, adapted from human-automation interaction, is being explored in human-AI teaming. In the current paper, we examine an essential component of trust that\u00a0\u2026", "issued": "@b{@cdate-parts@c:[[2022]]}@b"}